# DL Project 规范 Checklist

## 0. 项目前提

- [ ] 已明确任务类型（分类 / 回归 / 检测 / 序列 / 其他）。
- [ ] 已有清晰业务目标（具体场景 & 成功条件）。
- [ ] 数据已完成基础清洗（脏数据 / 严重异常已处理）。
- [ ] 已搭建可复用的训练 + 评估工作流（命令/脚本一键运行）。
- [ ] 有能力运行多次试验（并行或串行队列）。

## 1. 指标与数据划分

### 1.1 评估指标

- [ ] 定义单一标量指标 `Score`：
  - [ ] 列出业务相关指标（精度、召回、AUC、延迟、内存等）。
  - [ ] 标记 **Satisficing 约束**（必须满足的阈值）。
  - [ ] 选择一个 **Optimizing 指标** 作为主指标。
  - [ ] 明确如何从多指标得到单一 `Score`（可直接等于主指标）。

### 1.2 数据划分

- [ ] 划分集合：
  - [ ] Train：训练模型。
  - [ ] Dev (Validation)：选模型 / 选超参。
  - [ ] Test：最终报告 & 对外对比。
- [ ] Dev、Test 与未来部署场景尽可能同分布。
- [ ] 若 Train 分布与部署明显不同：
  - [ ] 从 Train 中再划出 Train-Dev（同分布子集）。
  - [ ] 计划比较 Train vs Train-Dev vs Dev/Test 以诊断数据不匹配。

## 2. Baseline 模型与训练配置

### 2.1 架构

- [ ] 选用与任务最接近的成熟模型家族：
  - [ ] CV：ResNet / EfficientNet / ViT / 等。
  - [ ] NLP：Transformer / BERT / 等。
- [ ] 选择 small / base 规模作为起点（而非最大模型）。
- [ ] 记录架构版本（便于追踪和对比）。

### 2.2 优化器

- [ ] 选择成熟优化器：
  - [ ] SGD + Momentum / Nesterov
  - [ ] AdamW / Adam / Adafactor
- [ ] 使用社区推荐默认超参起步（lr 除外）。
- [ ] 记录所有优化器超参（lr, β1, β2, ε, weight decay 等）。

### 2.3 Batch Size

- [ ] 通过实验确定硬件可承受的 batch 范围。
- [ ] 测试不同 batch 下的吞吐量（samples/sec）。
- [ ] 选择在吞吐量接近饱和前的较大 batch。
- [ ] 记录当前 batch size，将来如更改需重调：
  - [ ] 学习率
  - [ ] 正则化强度
  - [ ] 训练步数 / schedule

### 2.4 Baseline 训练配置

- [ ] 学习率 schedule：
  - [ ] 常数 / 线性衰减 / 余弦衰减（从中选一）。
- [ ] 初始 `max_train_steps`（经验或小实验估计）。
- [ ] 完成一次 baseline 训练：
  - [ ] Dev 指标显著优于随机。
  - [ ] 训练稳定无严重发散。

## 3. 调优循环（每一轮）

> 每轮只解决一个主要问题。

### 3.1 定义本轮目标

- [ ] 明确本轮唯一主问题，例如：
  - [ ] 架构对比（深度 / 宽度 / block 形式）。
  - [ ] 正则化方式（dropout / weight decay / label smoothing）。
  - [ ] 优化器 / lr 范围探索。
  - [ ] 数据增强策略。
- [ ] 禁止在一轮中同时大改多个维度（除非算力极其充足）。

### 3.2 设计研究（Study）

- [ ] 将超参分三类：
  - [ ] **目标超参**：本轮要回答的问题对象。
  - [ ] **冗余超参**：需为每个目标值调优的（lr、wd 等）。
  - [ ] **固定超参**：本轮不动。
- [ ] 为每个需要调的超参设置搜索空间（上下界 + 线性 / log）。
- [ ] 选择搜索算法：
  - [ ] 探索阶段：Quasi-random / random search。
  - [ ] 利用阶段：Bayesian optimization。
- [ ] 设定 trial 数量（受算力限制尽量多）：
  - [ ] 每个目标值下有多个不同冗余配置。
  - [ ] 整体覆盖搜索空间合理范围。

### 3.3 运行 & 分析

- [ ] 记录每个 trial 的：
  - [ ] 配置（超参组合）。
  - [ ] 全程训练曲线（Train / Dev）。
  - [ ] 最佳 Dev 指标（及对应 step）。
- [ ] 绘制并检查：
  - [ ] 超参轴图（x: 超参，y: Dev 指标）。
    - [ ] 最优点是否挤在边界？→ 考虑扩大搜索空间。
    - [ ] 是否有大量发散点？→ 检查稳定性 / 搜索空间上界。
  - [ ] 若干最优 trial 的训练曲线：
    - [ ] 是否明显过拟合（Dev 先降后升）。
    - [ ] 是否训练过早饱和（训练曲线长时间水平）。
    - [ ] 是否存在大梯度尖峰或异常波动。
- [ ] 诊断：
  - [ ] Train error 相对人类/理想误差很高 → 高偏差。
  - [ ] Train 低、Dev 高 → 高方差。
  - [ ] Train-Dev 好、Dev/Test 差 → 数据不匹配。
- [ ] 误差分析：
  - [ ] 抽取 Dev 错误样本（~100–200）。
  - [ ] 分类错误类型（场景 / 类别 / 标注问题）。
  - [ ] 找出占比最大且可干预的错误类型。

### 3.4 是否上线新配置

- [ ] 对新旧最佳配置各重复训练若干次（不同种子），估计训练方差。
- [ ] 若新配置提升 > 方差尺度，且复杂度可接受：
  - [ ] 设为新 baseline。
- [ ] 若提升有限或增加大量复杂度：
  - [ ] 暂不作为 baseline，只记录为经验。

## 4. 诊断与改进决策

### 4.1 偏差 / 方差 / 分布不匹配

- [ ] 高偏差（Train 高）→ 优先：
  - [ ] 更大 / 更深模型。
  - [ ] 更好的架构 / 特征。
  - [ ] 更长训练或稍大 lr。
  - [ ] 减弱正则。
- [ ] 高方差（Train 低，Dev 高）→ 优先：
  - [ ] 更多训练数据。
  - [ ] 更强正则（L2 / dropout / 数据增强）。
  - [ ] 减小模型容量。
- [ ] 数据不匹配（Train-Dev 好，Dev/Test 差）→ 优先：
  - [ ] 收集更接近 Dev/Test 的训练数据。
  - [ ] 对样本加权 / 域自适应。

### 4.2 标注质量

- [ ] Dev/Test 有明显错标：
  - [ ] 优先人工清洗，保证评估可信。
- [ ] Train 中存在系统性错标且集中在关键场景：
  - [ ] 规划专项重标或修订标注规则。

### 4.3 迁移学习 & End-to-End

- [ ] 目标数据有限，模态标准（图像 / 文本 / 语音）：
  - [ ] 优先使用预训练模型 + 任务头（迁移学习）。
- [ ] 端到端数据多，中间标签难得：
  - [ ] 可考虑 End-to-End 模型。
- [ ] 数据有限且中间子任务易注释：
  - [ ] 更推荐分阶段 pipeline。

## 5. 训练步数与稳定性

### 5.1 训练步数

- [ ] 判断当前模式：
  - [ ] 受计算限制：步数受预算限制。
  - [ ] 不受计算限制：可以足够久训练。
- [ ] 不受计算限制：
  - [ ] 用常数 lr 做小搜索，估计“接近完美拟合”所需步数。
  - [ ] 以此为 `max_train_steps` 起点，再由训练曲线微调。
- [ ] 受计算限制：
  - [ ] Round 1：使用较短训练（如 10–20% 最终预算）做广泛调参。
  - [ ] Round 2：在候选最佳配置上用接近最终预算训练。

### 5.2 稳定性（必须通过，才继续大规模调参）

- [ ] 检查是否有不稳定迹象：
  - [ ] 略增 lr 即 loss 爆炸 / NaN。
  - [ ] 梯度范数偶发巨大尖峰。
  - [ ] 训练初期 loss 突然大涨后缓慢恢复。
- [ ] 顺序尝试：
  - [ ] 学习率预热（warmup）：
    - [ ] 从 0 线性升至 target lr，扫描不同 warmup 步数。
  - [ ] 梯度裁剪：
    - [ ] 记录梯度范数分布，阈值取 ~90 百分位作为起点。
  - [ ] 架构规范：
    - [ ] 使用合理残差结构、归一化、初始化。
  - [ ] 最后手段：降低峰值学习率。

## 6. 工程与可复现性

### 6.1 输入管道 & 性能

- [ ] 使用 profiler 检查是否为 I/O / 数据管道瓶颈。
- [ ] 若是瓶颈：
  - [ ] 数据本地化 / 缓存。
  - [ ] 预处理尽量离线完成。
  - [ ] 使用 prefetch / 并行 map。
  - [ ] 多机时考虑数据服务 / 数据分片。

### 6.2 评估与 checkpoint

- [ ] 定期评估设置：
  - [ ] 使用 ≥ 训练 batch 的 eval batch。
  - [ ] 按固定 step 间隔评估（非时间间隔）。
- [ ] Checkpoint 策略：
  - [ ] 定期保存模型状态。
  - [ ] 支持训练后回顾式选择 Dev 最优 checkpoint。
- [ ] 保存：
  - [ ] 训练曲线数据。
  - [ ] 部分样本级预测（用于误差分析）。

### 6.3 实验记录

- [ ] 为每次研究记录：
  - [ ] 研究 ID / 名称。
  - [ ] 目标超参 & 冗余超参定义。
  - [ ] 搜索空间与搜索算法。
  - [ ] 每个 trial 的配置与 Dev 最佳指标。
  - [ ] 最佳 checkpoint 引用。
- [ ] 使用统一实验管理工具 / 表格，避免散落在个人笔记中。

### 6.4 多机 / 多设备

- [ ] 日志和 checkpoint 仅由一个主机负责写入。
- [ ] BN / 其他统计量在设备间正确同步。
- [ ] 初始化 seed 可控，数据 shuffle seed 可区分。
- [ ] 数据文件合理分片，避免单点热点。

## 7. 给 LLM / Agent 的执行顺序（简表）

1. [ ] 读取任务描述 → 抽取业务目标 & 任务类型。
2. [ ] 检查并补全：单一标量指标 + 约束 + 数据划分。
3. [ ] 若无 baseline：设计并输出 baseline 配置（架构 + 优化器 + batch + schedule + 步数）。
4. [ ] 根据用户意图 / 当前瓶颈，确定本轮唯一主目标。
5. [ ] 定义目标 / 冗余 / 固定超参 + 搜索空间 + 试验数量。
6. [ ] 输出一组 trial 配置（适合自动调度）。
7. [ ] 读取实验结果（或假定结果）→ 做：
   - [ ] 搜索空间边界分析。
   - [ ] 训练曲线分析。
   - [ ] Bias / Variance / mismatch 诊断。
   - [ ] 误差分析建议。
8. [ ] 评估是否更新 baseline，并给出下一轮推荐目标。
