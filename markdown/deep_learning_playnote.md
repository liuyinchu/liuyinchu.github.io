# Ysy's Deep Learning PlayNote

## 0. 适用范围与前提

* 任务假设：主要是**监督学习或类似范式**（包括自监督），但大部分方法可迁移到其它场景。
* 关注重点：

  * **超参数调优流程**（搜索空间、实验设计、分析与上线）
  * 兼顾工作流搭建、训练稳定性、数据与评估等工程细节
* 前置条件：

  1. 问题定义、数据清洗等基础工作已完成。
  2. 有一套能自动跑训练 + 评估的工作流。
  3. 已有合理的评估指标（尽量贴近部署时真正关心的指标）。

## 1. 整体工作流总览

可以把整个过程看成一条链：

> **业务目标 → 评估体系 → 数据划分 → 初始配置 → 实验 / 调优 → 误差分析 → 有针对性的改进**

关键思想：

1. **Orthogonalization（正交化）**

   * 每一步只解决一个问题：
     “目标怎么定义” 和 “模型怎么训练” 是两个不同决策。
2. **单一数值指标（single-number metric）**

   * 不管内部多少子指标，最后要能给每个模型一个**总分**，便于排序和决策。
3. **增量调优 + 快速 baseline**

   * 先搞出一个**能跑通的系统**，再用系统化实验一点一点改好。

## 2. 目标、指标与数据划分

### 2.1 单一标量评估指标

* 需要一个**单一数字**来衡量好坏：

  * 可直接用：AUC / F1 / mAP 等。
  * 或加权合成：例如 `Score = F1 - λ * latency`。
* 如果有多维约束（精度、延迟、模型大小等），区分：

  * **Satisficing metrics（“够用型”约束）**：只需达到阈值，例如 `latency ≤ 100ms`。
  * **Optimizing metric（优化型）**：在约束满足前提下要尽量极致，例如验证 F1。

**模型选择流程** = 先过滤掉不满足所有 Satisficing 约束的，再用单一 Optimizing 指标排序。

### 2.2 Train / Dev / Test 划分与数据不匹配

* 规范：

  * Train：拟合参数。
  * Dev：**选模型 / 选配置**。
  * Test：只做最后报告与对外比较。
* Dev / Test 应当：

  * 尽量来自**未来真实部署分布**。
  * 尽量互相同分布，否则 Test 没有说服力。
* 若 Train 数据来自廉价分布（公开数据、模拟数据），而 Dev/Test 来自线上：

  * 容易出现：Train & Train-Dev 表现好，Dev/Test 变差 → **分布不匹配**。
  * 做法：

    * 从 Train 分出一小部分作为 **Train-Dev**（同分布）。
    * 比较 Train vs Train-Dev vs Dev：

      * Train → Train-Dev 差很大：方差问题。
      * Train-Dev → Dev 差很大：**数据不匹配问题**。

解决数据不匹配：

* 尽量收集更多“像 Dev/Test”的训练样本。
* 对训练样本加权，让“像 Dev 的样本”权重大。
* 用域自适应方法做特征对齐 / 对抗训练等。

### 2.3 改变评估指标的时机

当出现：

* 指标很好，但业务体验很差；
* 人工检查错误样本感觉很糟糕，但指标不敏感；

说明 **指标不再反映真实目标**，应优先考虑：

1. 调整指标（权重、代价敏感、子类加权等）。
2. 重新划分 Dev 集，使其更代表业务场景。
3. 然后再谈模型改进。

### D. 模型与训练初始配置

#### D.1 选择模型架构

**原则**：新项目尽量从**已有成功架构**起步，而不是从零设计。

* 找与当前任务最接近的论文 / 开源模型，直接复现其 baseline。
* 把架构视作一个“家族”：层数、宽度、激活、block 形式等都是后续可调超参。

#### D.2 选择优化器

**原则**：起步用成熟、常用的优化器。

* 常见选择：

  * SGD with momentum（含 Nesterov）
  * Adam / NAdam（更通用，但超参更多）
* 注意：

  * 优化器往往带一堆超参（lr、momentum、β1、β2、ε…），**后面都要调**。
  * 项目初期，倾向使用**超参较少、行为易理解**的配置：

    * 固定动量的 SGD；
    * 固定 β1、β2、ε 的 Adam，把学习率当唯一主角，先把能跑通搞定。

#### D.3 选择 Batch Size

**核心结论**：Batch Size 是**训练速度 / 资源成本的决定因素**，
**不应**直接拿来当“提高验证集性能的调节旋钮”。

* 理论上：只要对每个 batch size **重新调好学习率 + 正则 + 步数**，
  不同 batch size 的**极限验证性能应接近**（Shallue et al. 2018）。
* 实际上，应主要从三个角度选：

##### D.3.1 可行范围 & 吞吐量

* 确定 GPU/TPU 能撑的 batch 上限（通常通过逐步加倍试）。
* 对每个候选 batch，测：

  * **训练吞吐量 = 每秒样本数**
  * 或 “每 step 时间”
* 若 batch 翻倍但吞吐量没明显提升，说明：

  * 训练 pipeline 出现瓶颈（I/O、同步等）；
  * 先**调 pipeline**，再考虑大 batch。

##### D.3.2 最小化训练时间

* 训练时间 ≈ 每 step 时间 × step 数。
* 在硬件未饱和前：

  * 每 step 时间近似不变；
  * 大 batch 一般需要**更少 step**达到同一效果。
* 通常实践：

  * 在不触发严重吞吐瓶颈的前提下，**用硬件能支持的尽量大的 batch**。
  * 但一旦增大 batch 导致训练时间反而变长，就不要再加。

##### D.3.3 资源消耗与成本

* 资源 = 每 step 的资源 × step 数。
* 大 batch：

  * 可能**省资源**（更高吞吐，同样目标用了更少总算力）。
  * 也可能**不变甚至更贵**（需要更多设备或更昂贵硬件）。
* 若扩大 batch 需要重构多机训练、改大量代码，且项目还早期，**可以先不做**。

##### D.3.4 超参与 Batch Size 的联动

* 换 batch size 几乎必然需要**重调：**

  * 学习率、动量等优化器超参；
  * 权重衰减、dropout 等正则超参；
  * 甚至训练步数 / schedule。
* 所以：**项目初期就尽量选好一个 batch，不要频繁切换**。

##### D.3.5 BatchNorm 的影响（只要用 BN 就绕不开）

* BN 的统计量与“用于计算 BN 的有效 batch”有关，而不是与优化器 batch 完全一致。
* 常用技巧：Ghost BatchNorm —— 训练时大 batch，BN 统计用固定小子 batch（如 32/64）。
* 多机时：

  * 数据分片 + BN 统计同步，细节容易出错；
  * EMA 统计的同步与保存也要小心。

#### D.4 初始配置（first run）

目标是找一个**简单、便宜、效果“合理”** 的起点配置，包括：

* 模型规模：先用较小模型。
* 优化器超参：固定简洁的 schedule（比如常数 lr 或简单衰减）。
* 训练步数：

  * 够长到“明显优于随机”，但不追求极致；
  * 后面根据训练曲线再调整。

## E. 用“科学方法”提高模型性能

### E.1 增量调优策略

目标不是凭感觉乱调，而是**迭代实验 + 学习问题结构**：

每一轮调优做四件事：

1. 选好这一轮**具体目标**（范围要窄）。
2. 设计实验：定义要调哪些“目标超参”，哪些当“冗余超参”去优化掉，哪些先固定。
3. 跑实验 + 分析结果（不只看最优点，还看整体结构）。
4. 决定是否把新的最佳配置“**上线**”（作为下一轮 baseline）。

### E.2 探索 vs 利用

实践中大部分时间应放在**探索问题**而非纯刷指标：

* 通过系统调参来回答问题：

  * 哪些超参对指标非常敏感？
  * 哪些正则化在这个任务上根本不起作用？
  * 哪些参数之间耦合强，需要一起调？
* 一旦对搜索空间结构了解够多，才进入“纯利用”阶段：

  * 用贝叶斯优化等工具在一个较小、优质的搜索空间中**榨干最后一点性能**。

### E.3 为每轮实验选目标

* 目标要**具体且可回答**，例如：

  * “更深的网络在充分调参后，Dev 上是否更好？”
  * “加入 dropout 是否有净收益？”
  * “某种数据增强是否有效？”
* 避免“一口吃太多”：一次只改变少数维度。

### E.4 目标超参 / 冗余超参 / 固定超参

* **目标超参**：本轮要研究的对象（如网络深度、是否使用 dropout）。
* **冗余超参**：必须在各个目标值下都尽可能调好，才能保证比较公平（如每种深度对应的学习率、权重衰减）。
* **固定超参**：暂时视为常量，不在本轮内调（比如激活函数、数据增强配置等）。

经验：

* 学习率、动量、Adam 的 β1/β2/ε 等**几乎总是冗余超参**，要认真调。
* “是否使用某种正则化 / 模块”（如 dropout、有无 LN / BN）往往是目标或固定超参。
* 模型结构超参（层数、宽度）通常也是目标或固定，而非“顺便调一调”。

### E.5 设计实验与搜索策略

* 每个目标超参配置都可以对应一个独立“研究”，在其中：

  * 固定目标超参；
  * 用某种**黑盒优化算法**（随机搜索 / Quasi-random / 贝叶斯）去优化冗余超参。
* 搜索算法：

  * **探索阶段**：

    * 更偏向 **Quasi-random search（低差异序列）**：

      * 采样均匀、实现简单；
      * 结果易解释（看边界是否有好点）。
      * 不依赖先前结果，所以批量并行非常自然。
  * **利用阶段**：

    * 进入已知“好区间”后，用贝叶斯优化等更聪明的方法在局部精调。

#### E.5.1 Quasi-random search 简要原则

* 比完全随机构点更均匀，比网格搜索在高维里有效得多。
* 优点：

  * 非自适应：可在事后自由更换评估指标，无需重跑。
  * 结果稳定、可复现，有利于长时间维护。
  * 在高度并行场景里，往往“2 倍预算的随机搜索”很难被复杂方法明显击败。

大致 trial 量级感：

* < 10 个 trial：只调最核心超参（比如 Adam 的 lr）。
* 10–25：可以加一两个重要维度（如 lr + β1）。
* 25+：可以逐渐把 ε、β2 等纳入搜索。

## F. 从误差角度理解问题

### F.1 Bayes 最优误差与可避免偏差

* **Bayes 最优误差**：在给定数据分布和内在噪声下，可达到的理论下限。
* 实际上常用**人类专家误差**作为 proxy。
* **可避免偏差 ≈ 训练误差 − Bayes / 人类误差**

  * Train 很高 → 高偏差（欠拟合）。
  * Train 接近人类 → 偏差几乎没空间，主要看方差 / 数据问题。

### F.2 Bias vs Variance 诊断

* 偏差高：

  * Train error 高，Dev 与 Train 差不多。
  * 对策：更大模型、训练更久、改架构、弱化正则。
* 方差高：

  * Train 误差低，Dev 明显变差。
  * 对策：更多数据、更强正则（L2、dropout）、数据增强、减小模型。

### F.3 误差分析（error analysis）

* 在 Dev 集上收集若干错误样本（100–200 条），人工标记错误类型：

  * 某类场景（光照、遮挡、小目标……）
  * 某类标签（少数类、难类）
  * 明显标注错误
* 统计各类错误占比 → 把精力优先放在**占比大且可通过工程手段改善**的错误上：

  * 专门收数据；
  * 专门数据增强；
  * 调整 architecture 专攻该类问题。

### F.4 是否清除错误标注

* Dev/Test：

  * 一旦错标比例不低，**必须优先清理**，否则评估本身不可信。
* Train：

  * 少量随机噪声通常不用太紧张。
  * 成片系统性错标且与关键场景相关时值得投入清理。

## G. 搜索空间与训练曲线的分析

### G.1 搜索空间边界是否合理

* 画“超参数轴图”（x：某超参；y：Dev 指标）：

  * 若最优试验**挤在边界附近**，说明搜索范围太窄，应往该方向扩。
* 看“不可行点”（loss NaN / 特别烂）：

  * 如果某侧大量点发散，那么稳定性限制了搜索空间上界，需要配合预热/裁剪等。

### G.2 采样是否够密

* 没有简单公式。
* 实际上用试验预算“推到上限”，再通过多次画轴图，训练直觉：

  * 好区域是否只有零星的点；
  * 多次重复搜索时最优值方差有多大。

### G.3 训练曲线检查要点

重点看“若干最优试验”的训练 & 验证曲线：

* 过拟合：

  * Dev 在某时刻开始上升；
  * 如果最好的几个试验都有严重过拟合，应优先加正则、重调学习率，而不是简单结论“模型太大”。
* 步间方差超大：

  * 尾部 loss / metric 上下乱跳，导致记录哪个 step 结束都很敏感；
  * 可能原因：batch 太小、validation 太小、lr 太大。
* 训练是否还在稳步变好：

  * 若后期仍明显改善 → 训练步数可能偏短（compute-bound）。
  * 若很早就平 → 训练时间可能浪费，可缩短步数或改变 schedule。

### G.4 Isolation plot（隔离图）

* 用来比较某一目标超参（例如权重衰减 λ）的“最佳效果”：

  * 对每个 λ，找在当前研究中对应的**最优试验**；
  * 把 λ 对应的这些最优 Dev 指标画出来。
* 可以看清：

  * 是否存在“最佳 λ 区间”；
  * 引入某个正则化技术是否在充分调参后仍有显著收益。

### G.5 自动可视化

* 尽量**自动化生成**：

  * 所有参与搜索的超参轴图；
  * 所有试验的训练曲线；
  * isolation 图。
* 越省事，你就越愿意看，也就越不容易被假象骗。

## H. 采用新配置：如何判断“值得上线”

观察到“新配置比旧 baseline 好”，但要考虑：

1. **试验方差**：同一超参，不同随机种子的结果差异。
2. **搜索方差**：随机搜索 / 贝叶斯优化本身带来的不稳定。
3. **数据抽样方差**：Dev 集有限大小自然导致的统计误差。

实践准则：

* 适当重复训练最优配置（多种 seed），估计**试验方差**。
* 如果新配置的提升**明显大于方差尺度**，且不会大幅增加工作流复杂度，就可以作为新 baseline。
* 否则保留为“候选方向”，但不要马上改掉当前基线。

## 8. 训练步数与多轮调参策略

### 8.1 受计算限制 vs 不受计算限制

* **受计算限制**：

  * 你愿意训练多久是瓶颈。
  * 更长训练 **理论上能进一步降训练误差**。
* **不受计算限制**：

  * 可以无限久训练；
  * 训练误差非常低，再多步对 Dev 提升边际极小甚至过拟合。

### 8.2 不受计算限制时：如何定 max_train_steps

* 目标：让训练时间**足够长能让模型“吃饱”**，但别浪费太夸张。
* 实践方式：

  * 用恒定学习率 + 不加正则，做一次小规模 lr 网格 / 搜索；
  * 找到能把训练误差降到“非常低”的试验；
  * 以它所需的步数作为一个初始 `max_train_steps` 估计。
* 之后通过训练曲线微调：

  * 如果最佳 checkpoint 总出现在 10% 以内 → `max_train_steps` 太大。
  * 如果总在训练末尾附近 → 可能还需要更多步或更合理的衰减 schedule。

### 8.3 受计算限制时：短跑 + 长跑

* 不要一开始就用“最终预算”跑所有试验：

  * 更好的方案是多轮：

    * Round 1：短训练（如 10% 预算）探索架构、正则、数据增强等。
    * Round 2：在较小候选集中，用接近生产预算的长训练确认结论。
* 超参的“可迁移性”大致排序：

  * 相对更稳定：

    * Warmup 长度；
    * 初始化方式。
  * 有一定可迁移性：

    * 模型架构（明显胜负的通常能迁移）。
  * 较不稳定：

    * 具体 lr schedule 的细节。
* 从 Round 1 到 Round 2：

  * 通常保持 peak lr，拉长高 lr 区间，再衰减；
  * 或按比例扩展整个 schedule（但要重新观察稳定性）。

## 9. 优化稳定性：先让它“好好收敛”

### 9.1 识别不稳定训练

现象：

* 学习率稍一变大，loss 就爆炸或突然跳高；
* 最优 lr 贴着“发散边界”；
* 梯度范数偶尔出现巨大尖峰。

诊断方法：

1. 做常数 lr 扫描，找到“最佳 lr*”。
2. 用略大于 lr* 的值画训练曲线：

   * 若训练曲线先降后突然暴涨 → 存在稳定性问题。
3. 记录梯度 L2 范数，观察是否有巨大 outlier。

### 9.2 学习率预热（warmup）

适用：**早期训练不稳定**。

* 思路：一开始从 0 线性爬到一个高的 base lr，再接原本的 schedule。
* 调法：

  * 先估一个会导致不稳定的 `unstable_lr`，再选 `base_lr` ≈ 5–10× `unstable_lr`。
  * 将 warmup 步数在几个量级上试：例如 10²、10³、10⁴ …，不超过总步数 ~10%。
  * 找到最短但足以稳定训练的 warmup 步数，再整合进 baseline。
* 若需要 >5–10% 的总步数来做 warmup，可能要适当增加总训练步数。

### 9.3 梯度裁剪

适用：**梯度偶发巨峰**（早期或中期）。

* 原则：

  * 记录无裁剪的梯度范数分布；
  * 取 ~90 百分位作为初始阈值；
  * 若仍不稳再逐步调低。
* 注意：

  * 一旦超过半数 step 都被重度裁剪，本质上是在用奇怪方式“减小 lr”，不如直接调小 lr。

### 9.4 架构与初始化规范

* 使用残差连接、标准归一化（BN/LN）和合理 init。
* 残差结构建议用 `x + Norm(f(x))`，而不是 `Norm(x + f(x))`。
* 可考虑把残差分支前的 scale 参数初始化为 0（ReZero 风格），减轻深层不稳定。

## 10. 训练 / 评估 / 实验基础设施

### 10.1 输入管道优化

常见瓶颈：

* 数据不在本地、跨网络读取；
* 线上复杂预处理放在训练时做；
* 管道中出现隐式同步屏障（如跨设备数据聚合）。

常用手段：

* 使用框架提供的 prefetch、并行 map 等；
* 尽早丢弃不必要的字段；
* 适当使用数据服务 / 多进程生成数据。

### 10.2 定期评估

* 目的：实时监控训练、做回顾式 checkpoint 选择、分析曲线。
* 建议：

  * 用尽可能大的 eval batch（不算梯度，便宜）。
  * 按**固定 step 间隔**评估，而不是按时间。
  * 对评估数据做合理采样：

    * 总量够小以便快速评估；
    * 但要能代表整体分布，对不平衡数据注意少数类表现的方差。

### 10.3 Checkpoint 与最佳点选择

* 定期保存模型状态（容错 + 后续分析）。
* 训练结束时，不一定选“最后一步”，而选：

  * **训练中 Dev 表现最好的若干 checkpoint**中的最佳。
* 事先约定试验步数预算，再回顾选择 checkpoint，一般不再需要复杂 early-stop 逻辑。

### 10.4 实验跟踪

* 至少记录：

  * 实验名 / 描述；
  * 配置文件或代码版本的链接；
  * trial 数量；
  * 最佳 Dev 指标；
  * 运行命令。
* 用任何你顺手的工具（表格 / 实验管理平台），关键是**不要靠记忆**。

## 11. BatchNorm 与多主机细节

* 多机时要注意：

  * 日志 / checkpoint 只在一个主机写；
  * BN 统计与 EMA 正确同步；
  * 初始化 seed 一致，数据打乱 seed 区分开；
  * 数据文件合理分片，避免热点。

## 12. 迁移学习与 End-to-End

### 12.1 迁移学习

适用：目标任务数据不大，但与某个大数据集任务在输入形态上类似。

* 策略：

  * 选预训练模型；
  * 数据少 → 冻结大多数层，只训练头部；
  * 数据中等 → 部分或全部解冻微调。
* 好处：降低偏差、提高样本效率。

### 12.2 End-to-End 模型

* 优点：

  * 从原始输入到输出，减少人为设计子模块的约束；
  * 数据足够大时，可能学到更优的中间表示。
* 风险：

  * 极度吃数据；
  * 难调试、难插规则、难解释。
* 原则：

  * 数据巨量 & 中间标注难得 → 倾向 End-to-End；
  * 数据有限 & 中间子任务易定义 → 分阶段 pipeline 往往更稳。

## 13. 常见问题速记

* **学习率衰减方案用什么默认？**

  * 常用：线性衰减或余弦衰减；关键是**用某种非恒定方案并调一调**。
* **为什么论文里 schedule 看起来那么复杂？**

  * 多数是作者根据验证集表现“人肉调 schedule”一步一步修补出来的。
  * 不建议生硬照搬，建议复制“方法论”而非具体折点。
* **Adam 超参怎么调？**

  * trial < 10：只调学习率；
  * 10–25：加上 β1；
  * 25+：再加 ε；
  * 预算特别足再考虑 β2。
* **为什么不用 batch size 直接刷指标？**

  * 在每个 batch size 都把 lr/正则/步数调到位后，极限性能差异通常很小；
  * Batch size 主要是速度 / 成本 / 稳定性决策，而不是“性能捷径”。
* **为什么这些叫“超参数”？**

  * 严格贝叶斯意义上这词被滥用了，更准确叫“元参数”更合适；
  * 但社区已经习惯把 lr、架构参数等统称 hyperparameters，只能继续沿用。
* **常见优化算法更新式（简表）**

  * SGD：
    $\theta_{t+1} = \theta_t - \eta_t \nabla \mathcal{l}(\theta_t)$
  * Momentum：
    $v_{t+1} = \gamma v_t + \nabla \mathcal{l}(\theta_t)$，
    $\theta_{t+1} = \theta_t - \eta_t v_{t+1}$
  * Adam：
    $m_{t+1} = \beta_1 m_t + (1-\beta_1)g_t$
    $v_{t+1} = \beta_2 v_t + (1-\beta_2)g_t^2$
    $\theta_{t+1} = \theta_t - \alpha_t \dfrac{\hat m_{t+1}}{\sqrt{\hat v_{t+1}}+\epsilon}$
    （带偏差校正）

---
---

## 附录：CHECKLIST

### A 总原则

* **[MUST] 单一目标驱动**：所有决策围绕同一个明确业务目标和评估指标。
* **[MUST] 正交化**：

  * 先定目标 & 指标
  * 再定数据划分
  * 再定模型 & 训练配置
  * 最后才是局部花活（正则、技巧等）。
* **[MUST] 迭代而非一次性**：永远围绕“下一轮实验目标”做最小必要改动。
* **[SHOULD] 尽量用成熟方案起步**：架构、优化器、schedule、工具优先选社区成熟选项。
* **[MUST] 一切结论来自实验，而不是直觉。**

### B 项目前提检查

**目标**：确认“值得进入调参阶段”。

* **[CHECK] 问题定义**

  * 任务类型是否明确：分类 / 回归 / 检测 / 序列等。
  * 监督信号是否清楚（标签含义、噪声特性）。
* **[CHECK] 数据基础**

  * 是否完成基本清洗：明显脏数据、重复、严重异常已处理。
  * 训练数据量级是否足以支撑计划中的模型规模。
* **[CHECK] 工作流**

  * 是否有“一键训练 + 一键评估”的 pipeline。
  * 是否支持批量试验（至少 N 个 trial 并行或串行队列）。

> 任一项不满足：先解决，不要急着调参。

### C 指标与数据划分规范

#### C.1 评估指标设计

* **[MUST] 定义单一标量指标 `Score`**

  * 若只有一个关键指标（如 AUC），则 `Score = AUC`。
  * 若多维：

    * 定义一组 **Satisficing 约束**（如 `latency ≤ 100ms`，`model_size ≤ X`）。
    * 定义一个 **Optimizing 指标**（如 F1），`Score` 基于它。
* **[DECIDE]**

  * 约束列表：`{latency, memory, size, fairness...}` 的阈值。
  * 最终优化指标：`Score` 的公式（可以很简单）。

#### C.2 Train / Dev / Test 划分

* **[MUST] 划分**

  * Train：用于拟合参数。
  * Dev：用于选模型 / 选配置。
  * Test：只在关键里程碑使用。
* **[MUST] 分布要求**

  * Dev、Test 必须尽可能贴近 **未来部署分布**。
  * Dev 与 Test 应当尽量同分布。
* **[IF] Train 分布 ≠ 部署分布 →**

  * **[MUST] 引入 Train-Dev**：从 Train 分布中再划一份 Train-Dev，用于区分“过拟合 Train”与“分布不匹配”。

### D 初始模型与训练配置

#### D.1 模型架构选择

* **[MUST]** 以“最近任务的成熟模型”为起点：

  * 找 1–2 篇近期相关论文 / 开源 repo。
  * 选其中最常用、最稳定的 backbone。
* **[DECIDE]**

  * 模型族：如 ResNet / ViT / Transformer / LSTM...
  * 规模等级：small / base / large（优先 small 或 base）。

#### D.2 优化器选择

* **[MUST]** 从以下中择一：

  * 图像 / CV：SGD+Momentum / Nesterov 或 AdamW。
  * NLP / Transformer：AdamW / Adafactor（如需要）。
* **[DECIDE] 初始优化器配置**

  * 学习率（lr）初值。
  * 对 Adam：`β1, β2, ε` 先用社区推荐默认（除非已有经验）。

#### D.3 Batch Size 策略

* **[MUST] Batch Size 不用于“直接刷指标”**，只用于**速度 / 成本 / 稳定性**决策。
* **[CHECK] 可行范围**

  * 用 2^k 试几个 batch，找到不 OOM 的最大值。
  * 记录每个 batch 的吞吐量（samples/sec）。
* **[DECIDE] Batch Size**

  * 在“吞吐量接近线性提升的上限附近”的值上选择；
  * 同时考虑资源成本和实现复杂度。
* **[WARN]** 一旦换 batch size → **必须重新调 lr、正则、步数**。

#### D.4 初始配置（Baseline）

* **[DECIDE] 初始配置 内容：**

  * 模型：选定家族 + 规模。
  * 优化器及其默认超参。
  * Batch Size。
  * 学习率 schedule：常数 / 线性衰减 / 余弦衰减（三选一）。
  * 训练步数 `max_train_steps` 初始估计（经验或小实验）。
* **[CHECK] Baseline 要求**

  * 能稳定训练到“明显优于随机”的 Dev 指标。
  * 每次训练的成本在可接受范围内。

### E 调优循环（核心流程）

每一轮调优必须遵循：

> **Step 1：定目标 → Step 2：设计研究 → Step 3：跑实验 & 分析 → Step 4：是否上线**

#### E.1 Step 1 – 定义本轮目标

* **[MUST] 给本轮设一个清晰问题，示例：**

  * “更深的网络是否在同等调参下更好？”
  * “加入 dropout 是否有净收益？”
  * “哪段学习率范围是合理的？”
* **[FORBID] 一轮内尝试解决多个大问题**（例如同时改架构 + 数据分布 + 优化器）。

#### E.2 Step 2 – 设计研究（Study）

* **[MUST] 分类超参**

  * **目标超参**：本轮要回答的问题对象（如 depth、是否用 aug）。
  * **冗余超参**：必须为每个目标值调好的（如 lr、权重衰减）。
  * **固定超参**：本轮不动的（如激活函数、某些正则）。
* **[DECIDE] 搜索策略**

  * 探索阶段：优先 **Quasi-random / uniform random search**。
  * 利用阶段：可以改用 **Bayesian optimization**。
* **[DECIDE] 搜索空间**

  * 为目标和冗余超参定义上下界（log 范围给 lr/正则）。
  * 条件超参（不同 optimizer 的不同参数）要单独定义。
* **[DECIDE] Trial 数量**

  * 受算力限制，尽量大；至少确保：

    * 每个目标值下有多个不同冗余配置。
    * 整体能覆盖到“合理范围”的一部分。

#### E.3 Step 3 – 运行并分析实验

* **[MUST] 不只看最佳 trial 的一个数字**：

  * 画超参轴图：`x = 超参，y = Dev Score`。
  * 检查：

    * 最优点是否挤在边界（→ 搜索空间太窄）。
    * 是否有大量不可行点（NaN / 爆炸）。
  * 看训练曲线（至少前几名 trial）：

    * 是否明显过拟合；
    * 是否训练过早饱和；
    * 是否存在巨大梯度尖峰或不稳定。
* **[CHECK] Bias / Variance / 数据不匹配定位**

  * Train 高、Dev 同样高 → 高偏差。
  * Train 很低、Dev 高 → 高方差。
  * Train-Dev 好、Dev/Test 差 → 数据分布不匹配。
* **[CHECK] 误差分析**

  * 抽错样本 N 条（100–200），进行人为归类。
  * 找出**占比最大且可干预**的错误类型。

#### E.4 Step 4 – 是否上线新配置

* **[CHECK] 提升是否超出方差**

  * 对新旧最优配置各重复训练若干 seed。
  * 提升幅度 > 训练方差（rough）才考虑上线。
* **[DECIDE] 上线条件**

  * 新配置的复杂度（实现、维护、性能成本）是否值得。
  * 如果只是小幅提升但明显增加工作流复杂性，谨慎上线。
* **[ACTION]**

  * 若上线：更新 baseline，并作为下一轮起点。
  * 若不上线：记录结果 + 经验，列入“无效尝试”知识库。

### F 诊断与改进决策树

#### F.1 偏差 / 方差 / 数据不匹配

* **[IF] Train error ≫ Human/Bayes error → 高偏差**

  * **[DECIDE] 优先动作：**

    * 换更大/更深模型；
    * 改架构（更合适 inductive bias）；
    * 延长训练 / 调大学习率；
    * 减弱正则。
* **[IF] Train error 低，但 Dev error 明显高 → 高方差**

  * **[DECIDE] 优先动作：**

    * 收更多训练数据；
    * 增强正则（L2、dropout、数据增强）；
    * 减小模型规模；
    * 早停 / 较强 lr 衰减。
* **[IF] Train & Train-Dev 指标好，但 Dev/Test 差 → 数据不匹配**

  * **[DECIDE] 优先动作：**

    * 收集与 Dev/Test 分布更接近的训练数据；
    * 对训练样本加权（domain reweighting）；
    * 引入 domain adaptation 方法。

#### F.2 标注质量与清洗

* **[CHECK] Dev/Test 中的错标占比**

  * 若影响排名 / 决策：**优先清洗 Dev/Test**。
* **[CHECK] Train 中是否有系统性标注错误**

  * 若集中在关键场景或某几类，并且数量可观：考虑专项重标。

#### F.3 何时使用迁移学习与 End-to-End

* **[IF] 目标数据不大，输入模态标准（图像 / 文本 / 语音）**

  * **[DECIDE] 迁移学习优先**：

    * 用预训练模型 + 任务头；
    * 数据少 → 冻结底层，仅训头部；
    * 数据多 → 解冻更多层微调。
* **[IF] 中间子任务标签难得 & 有大量端到端数据**

  * **[DECIDE] 可考虑 End-to-End**：

    * 但前提是算力足/数据多；
    * 需要接受调试与解释更困难的代价。
* **[IF] 数据有限且可轻松标注中间阶段**

  * **[DECIDE] 优先分阶段 pipeline，而非 End-to-End**。

### G 训练步数与稳定性规范

#### G.1 训练步数策略

* **[MUST] 明确当前是：**

  * 受计算限制：步数受预算限制。
  * 不受计算限制：可足够久。
* **[策略]**

  * 不受计算限制：

    * 用恒定 lr 做一次小搜索，估算“接近完美拟合”的步数作为 `max_train_steps` 起始值。
    * 再通过训练曲线校正。
  * 受计算限制：

    * 多轮策略：

      * Round 1：短跑（如 10–20% 预算）广泛调参。
      * Round 2：在少量候选配置上跑接近最终预算确认。

#### G.2 优化稳定性规范

* **[CHECK] 是否存在不稳定迹象**

  * 学习率稍放大就 loss 爆炸；
  * 梯度范数出现偶发巨大尖峰；
  * 训练初期某段 loss 突然上升后缓慢恢复。
* **[DECIDE] 处理顺序**

  1. 尝试学习率预热：

     * 从 0 线性升到 target lr，扫描不同 warmup 步数。
  2. 尝试梯度裁剪：

     * 记录梯度范数分布，以 ~90 百分位作阈值起点。
  3. 检查架构：

     * 是否有合理残差、归一化、初始化。
  4. 最后手段：降低峰值 lr。
* **[FORBID] 在明显不稳定的训练上做大规模调参**。

### H 工程与可复现性规范

#### H.1 输入管道 & 训练效率

* **[CHECK] 是否存在 I/O 瓶颈**

  * 训练吞吐 vs 理论峰值差距；
  * 监控数据读取时间占比。
* **[DECIDE]**

  * 本地化数据 / 缓存；
  * 预处理尽量离线；
  * 使用 prefetch / 并行数据加载；
  * 在多机场景使用数据服务 / 分片策略。

#### H.2 评估与 checkpoint

* **[MUST] 定期评估设置**

  * 使用 ≥ 训练 batch 的 eval batch；
  * 在固定 step 间隔评估（非固定时间）。
* **[MUST] Checkpoint 策略**

  * 定期保存模型；
  * 支持在训练结束后**回顾式选择 Dev 最优 checkpoint**。
* **[SHOULD] 记录部分样本级预测**

  * 方便误差分析和调试。

#### H.3 实验追踪

* **[MUST] 为每个研究 / 实验记录至少：**

  * 实验 ID / 名称；
  * 所有重要超参配置；
  * 代码 / 配置文件版本；
  * trial 数与每个 trial 的 Dev 指标；
  * 最佳 checkpoint 标识。
* **[SHOULD] 使用统一的实验管理工具或至少共享表格**。

#### H.4 多机 / 多设备规范

* **[CHECK]**

  * 日志与 checkpoint 只由一个主机负责。
  * BN / 其他统计量在设备之间正确同步。
  * 初始化 seed / 数据 shuffle seed 区分清晰但可控。
  * 数据在设备间适当分片。

### I 给 LLM / Agent 的运行提示

当 LLM / Agent 执行“帮我优化一个 DL 项目”时，**建议按以下顺序自检：**

1. **[Check] 是否有：单一业务目标 + 单一标量指标 + 约束列表？**
2. **[Check] 数据划分：Train / Dev(/ Train-Dev) / Test 是否合理？**
3. **[Check] 是否已选择成熟架构 + 合理优化器 + 固定 batch？**
4. **[Check] 是否存在稳定、可重跑的 baseline？**
5. **[Decide] 当前轮次的唯一目标是什么？（架构 / 正则 / lr / 数据 / 迁移学习……）**
6. **[Plan] 将所有超参分类：目标 / 冗余 / 固定，设计一个研究 + 搜索空间 + trial 数。**
7. **[Analyze] 实验后：**

   * 看搜索空间边界；
   * 看训练曲线；
   * 做 bias/variance/mismatch 判断；
   * 做误差分析。
8. **[Decide] 是否上线新配置？**
9. **[Loop] 更新 baseline，进入下一轮；若搜索空间已成熟 → 切到贝叶斯优化。**

上述 CHECKLIST 的 `.md` 文件可以在[笔记](\notes)中获取。