# 智能增强的非线性动力学数据驱动建模 · 研究现状

## 建模与辨识：概念框架

### 动力系统建模的基本概念

动力系统建模的根本目标，是以数学形式刻画系统状态随时间演化的规律。从形式上看，给定系统的状态变量、输入变量以及相应的结构与参数（或算子），动力学模型试图描述状态在时间轴上的演化映射关系。对于连续时间系统，这一关系通常表示为微分方程或微分代数方程；对于离散时间系统，则表现为差分方程或递推映射。以最常见的状态空间形式为例，连续时间动力系统可写为
$$\dot{x}(t)=f\big(x(t),u(t),t;\theta\big),\qquad y(t)=g\big(x(t),u(t),t;\theta\big),$$
其中 $x(t)\in\mathbb{R}^n$ 表示系统状态，$u(t)$ 为外部输入，$y(t)$
为可观测输出，$f(\cdot)$ 与 $g(\cdot)$
分别刻画系统的内部动力学与观测机制，$\theta$ 表示模型参数或算子集合。

需要强调的是，系统模型并非真实系统的等价替代，而是其近似表示。模型的作用在于捕捉支配系统行为的关键动态结构、内在模式及变量间关系，从而为分析、预测与控制提供可操作的数学载体。正如系统辨识领域的经典观点所指出的，数学模型与物理系统属于不同层次的对象，模型的"有效性"并不体现在对现实的完全复现，而体现在其对研究目标相关动态特性的合理刻画。因此，任何动力学建模过程本质上都隐含着抽象、简化与近似。

在这一背景下，模型精度与模型复杂度之间的权衡构成动力系统建模的核心问题。一方面，引入更多状态变量、更高阶非线性项或更复杂的算子结构，通常能够提高模型对观测数据的拟合能力；另一方面，过度复杂的模型不仅增加参数估计与计算负担，还可能导致过拟合、可解释性下降以及泛化能力不足。尤其在非线性系统中，复杂动力学现象（如多稳态、分岔与混沌）往往诱使模型结构迅速膨胀，使这一权衡问题更加突出。由此，建模的目标并非"尽可能复杂"，而是在给定任务需求下，构造结构简洁且动态表达能力充足的模型。

从模型表达形式来看，动力系统模型可沿多个维度进行分类。首先，根据时间刻画方式的不同，可区分为连续时间模型与离散时间模型，二者分别适用于物理连续过程与采样系统。其次，依据不确定性的处理方式，模型可分为确定性模型与随机模型，后者通过显式引入噪声或随机过程来描述测量误差与内在扰动。第三，从变量组织形式上，可区分为输入--输出模型与状态空间模型：前者直接建立输入与输出之间的映射关系，后者则显式引入状态变量以揭示系统内部动力学结构。进一步地，根据方程是否可显式求解，还可区分显式模型与隐式模型；而在维数层面，则存在低维模型与高维模型之分，高维模型常需借助降维或模型约简技术以提升可操作性。

综上所述，动力系统建模是一项在物理机理、数学表达与应用需求之间不断权衡的过程。模型形式的选择不仅决定了系统行为能够被刻画的方式，也直接影响后续系统辨识与分析方法的可行性与有效性。

### 系统辨识的基本概念

系统辨识是根据观测数据构建动力系统数学模型的基本方法，其核心思想在于利用有限的实验或运行数据，对未知或不完全已知的系统进行建模与刻画。经典定义指出，系统辨识旨在"从观测数据中确定用于描述实际系统的模型结构形式及其参数"，从而建立一个在特定意义下能够代表真实系统行为的数学模型。从更广义的科学视角看，从观测数据中提炼模型并揭示其内在属性，本身正是科学研究的基本范式，而系统辨识正是这一范式在动力系统领域中的集中体现。

形式上，系统辨识通常建立在输入--输出数据或状态观测数据之上。设离散时间动力系统可表示为
$$y(k)=\mathcal{M}\big(y(k-1),\ldots,u(k),u(k-1),\ldots;\theta\big)+e(k),$$
其中 $\mathcal{M}(\cdot)$ 表示模型结构，$\theta$ 为参数向量，$e(k)$
为噪声或未建模动态。系统辨识的目标，正是通过有限长度的数据序列
$\{u(k),y(k)\}_{k=1}^N$，确定合适的模型类别 $\mathcal{M}$ 及其对应参数
$\theta$，并使模型在预测误差、统计一致性或动态行为等意义下与真实系统尽可能一致。

由于研究对象与应用背景的差异，系统辨识问题呈现出多样化的研究任务类型。参数辨识是最为基础的一类问题，其前提是模型结构形式已知，仅需通过数据估计未知参数。例如，在给定状态空间模型
$$x(k+1)=A(\theta)x(k)+B(\theta)u(k),$$
的情况下，参数辨识的目标是确定矩阵 $A,B$
中的参数。对于线性系统，由于其输入--输出关系满足叠加原理，系统阶次或结构指标往往可通过相关分析或子空间方法加以确定，而参数则可通过最小二乘、极大似然或递推估计算法获得。

然而，在许多实际系统中，模型结构并非事先已知，或仅掌握部分先验信息，此时问题自然转向结构辨识或模型发现。该任务不仅需要估计参数，还需从候选模型集合中选择合适的结构形式，甚至直接从数据中发现动力学方程或算子表达。这一问题在非线性系统中尤为突出：非线性项的组合方式、耦合结构及维数选择高度不确定，使得结构辨识成为系统辨识中最具挑战性的环节之一。正如非线性系统辨识的综述工作所指出的，结构选择往往对最终模型质量起决定性作用，其难度和重要性均显著高于参数估计本身。

除上述两类核心任务外，系统辨识还涵盖状态估计与滤波问题，即在系统状态不可完全观测或存在噪声干扰的情况下，通过模型与数据联合估计系统内部状态；以及闭环辨识问题，即在反馈控制作用下获取数据并进行辨识，此时需特别处理由控制输入与噪声相关性引入的辨识偏差。这些问题在控制与信号处理领域具有重要应用价值，但其研究重点与方法论侧重与建模任务本身有所不同。

在本文关注的"智能增强的非线性系统数据驱动建模"背景下，系统辨识的讨论将聚焦于参数辨识与结构辨识两类任务，其中尤以后者为核心。原因在于，非线性系统中结构不确定性往往主导建模难度，而智能与数据驱动方法的引入，正是为了突破传统方法在结构发现与复杂模型选择方面的局限。

### 建模与辨识的关系

在动力系统研究中，"建模"与"辨识"常被并置使用，但二者在概念内涵与方法论侧重点上存在明确区分。建模侧重于模型类别与表达形式的设定，即回答"采用何种数学语言来描述系统动力学"；而辨识侧重于在既定模型类别中，利用数据确定具体模型，即回答"该模型的结构细节与参数取值为何"。这种区分在系统辨识的经典框架中已被反复强调：模型必须隶属于一个与研究目标相一致的模型类，而辨识过程则是在该模型类中进行选择与估计。

从形式化角度看，建模可被理解为确定一个模型类
$$\mathcal{M}_c=\left\{\mathcal{M}(\cdot;\theta)\mid \theta\in\Theta\right\},$$
其中 $\mathcal{M}_c$
规定了模型的结构形式、变量组织方式以及允许的非线性类型；$\Theta$
则为参数空间。在此基础上，系统辨识问题可表述为一个基于数据的优化或推断问题：
$$\hat{\theta}=\arg\min_{\theta\in\Theta}\;\mathcal{J}\big(\mathcal{M}(\cdot;\theta),Z\big),$$
其中 $Z$ 表示观测数据集，$\mathcal{J}(\cdot)$
为误差准则或似然函数。由此可见，建模先行，辨识随后是传统系统理论中最为常见的流程假设。

然而，建模与辨识并非相互独立的两个阶段，而是存在紧密的相互依赖关系。一方面，建模假设直接限定了辨识的搜索空间：模型类别的选择决定了哪些动态特征能够被表达、哪些结构根本不可能通过辨识得到。例如，若模型类被限定为线性结构，则无论数据多么丰富，非线性动力学现象均无法通过辨识显式呈现。另一方面，辨识结果又反过来对建模假设进行检验与修正。若在给定模型类中无法获得统计意义上令人满意的模型，往往意味着原有建模假设与系统真实行为不相容，需要重新审视模型结构、维数或不确定性描述方式。

这种双向作用在非线性系统中尤为显著。非线性系统的动力学结构高度多样，模型结构的不确定性显著增强，使得单纯"先建模、后辨识"的顺序过程面临局限。一方面，过于简化的建模假设可能导致系统关键非线性特征被忽略；另一方面，过于宽泛的模型类又会引发维数灾难与过度参数化问题，从而削弱辨识的可行性与可靠性。相关研究指出，在非线性系统辨识中，结构选择与参数估计往往高度耦合，难以严格分离为两个独立步骤。

在数据驱动与智能方法兴起的背景下，建模与辨识的关系正在发生重要转变。二者逐渐由传统的顺序式过程转向协同式过程：模型结构不再完全依赖人工先验设定，而是通过数据驱动方法在辨识过程中逐步涌现；与此同时，参数学习与结构发现往往在同一优化或推断框架内同时进行。例如，可将结构选择问题嵌入到正则化或稀疏化的辨识目标中：
$$\min_{\theta}\; \mathcal{J}(\theta)+\lambda\,\mathcal{R}(\theta),$$
其中正则项 $\mathcal{R}(\theta)$
用于诱导模型结构的简化或稀疏，从而实现结构与参数的联合学习。

综上所述，建模与辨识既在概念上有所区分，又在方法论上相互制约、彼此支撑。特别是在非线性与数据驱动建模背景下，二者的协同演化构成了现代系统辨识的重要特征。

### 动力系统建模的基本方法

在前文对"建模---辨识"关系的辨析中，我们已强调：建模假设规定了辨识的搜索空间，辨识结果又反向检验并修正建模假设。由此自然引出一个更具方法论意义的问题：在非线性与复杂系统背景下，应当选择怎样的模型信息来源与表达范式，才能在可解释性、数据依赖性与外推鲁棒性之间取得合理平衡？围绕这一问题，系统辨识与动力学建模实践中形成了"白盒---黑盒---灰盒"的谱系视角，用以刻画从机理主导到数据主导的连续体。

从信息来源看，系统辨识与数据驱动建模中的模型通常可归纳为三类：白盒模型（white-box）、黑盒模型（black-box）与灰盒/混合模型（gray-box/hybrid）。当系统本质、基本原理或基本定律较为明确时，可由守恒律、本构关系与边界条件推导出机理模型（亦称一阶原理/解析/知识驱动模型）；相对地，当系统复杂到难以在基本层面理解时，数据驱动方法作为一阶原理方法的实用替代方案，通过计算与统计手段从输入--输出数据中识别规律。基于此，机理模型因内部机制清晰而被称为白盒模型，数据驱动模型因内部机制相对不透明而被称为黑盒模型；融合二者特征的混合建模可视为灰盒模型，其结构通常由"机理部分 +
数据部分"构成。

这一三分法并非割裂的类别学，而更接近一个由多维指标刻画的连续体。可用于描述该连续体的关键维度至少包括：先验物理知识占比、结构可解释性、数据需求量、以及在工况变化下的可外推性与鲁棒性。例如，白盒模型往往以高可解释性与外推能力为代价，承担较高的机理建模与参数校准成本；黑盒模型则以较低的建模门槛换取对数据与激励设计的高度依赖，并引入可解释性与外推风险。灰盒模型的基本思想，是将物理先验作为结构性约束注入学习过程，从而在精度与可解释性之间实现折中。

更重要的是，复杂工程系统中"机理不完备"已成为常态：原型测试中常出现线性模型无法可靠预测的非线性现象（如跳跃、次/超谐共振、模态耦合与混沌等），迫使建模范式向更强的数据驱动或混合方向迁移。

白箱建模的基本路径可概括为：物理定律/本构/边界条件
$\rightarrow$（离散化/降阶）$\rightarrow$
可计算的动力学方程形式。以力学与结构动力学为代表，连续介质或多体系统经加权残值法、有限元等离散化后，常得到如下常微分方程组（向量形式）：
$$M\ddot{x}(t)+C\dot{x}(t)+Kx(t)+\mathcal{N}(x,\dot{x},z)=p(t),\qquad \dot{z}(t)=f(x,\dot{x},z),$$
其中 $x(t)\in\mathbb{R}^N$ 为广义坐标，$M,C,K$
分别为质量、阻尼与刚度矩阵，$\mathcal{N}$
汇集几何非线性、材料非线性、摩擦滞回与接触等复杂效应所对应的非线性项或内部变量力，$p(t)$
为外载，$z(t)$
为描述记忆/滞回等效应的内部变量。为降低维数并便于分析与控制设计，常进一步采用线性模态投影
$x=B_0 q$ 得到模态坐标形式
$$\ddot{q}(t)+D\dot{q}(t)+\Lambda q(t)+\widetilde{\mathcal{N}}(q,\dot{q},z)=u(t),\qquad \dot{z}(t)=\hat{f}(q,\dot{q},z),$$
其中 $\Lambda$ 与 $D$
分别对应固有频率与阻尼的对角形式（或近似对角形式），$q(t)$
为模态坐标，$u(t)$ 为模态激励。

白箱模型的主要优势在于：其结构直接反映物理机制，便于进行稳定性、可控性与鲁棒性分析，并可为控制器设计提供可解释的结构性依据；同时，若机理假设成立，其对工况变化往往具有更好的外推能力。

其边界也同样明确：一方面，复杂非线性（材料非线性、摩擦滞回、间隙接触等）在机理层面难以精确建模，且参数获取与校准成本高；另一方面，工程系统原型测试中频繁出现非线性失配，使得"基本机理正确但细节不完备"的情形十分普遍，导致仅靠白箱模型难以达到所需可靠性。

黑箱建模的基本思想，是直接学习输入--输出映射或状态演化映射，而不要求模型结构在物理层面可解释。与前文"辨识在给定模型类中确定具体模型"的表述一致，黑箱建模的关键首先在于模型类
$\mathcal{M}_c$ 的选择，其次才是参数估计。

在传统系统辨识中，黑箱模型常采用结构化回归形式，例如线性 ARX/ARMAX
模型：
$$y(k)=\sum_{i=1}^{n_y} a_i\,y(k-i)+\sum_{j=1}^{n_u} b_j\,u(k-j)+e(k),$$
以及其非线性扩展 NARX/NARMAX：
$$y(k)=F\!\big(y(k-1),\ldots,y(k-n_y),u(k-1),\ldots,u(k-n_u)\big)+e(k),$$
其中 $F(\cdot)$
可取多项式、径向基、核方法或神经网络等。相应地，现代数据驱动建模进一步引入深度网络序列模型、编码器---解码器结构与可逆生成模型等，以更强的表示能力处理高维与强非线性动力学。

从方法论角度，黑箱范式的重要支撑在于"通用逼近"思想：在适当条件下，足够表达能力的非线性模型族可以在函数空间意义上逼近广泛的系统映射，因此具有很强的表示通用性。

黑箱模型的主要瓶颈也与其范式特征一致：其性能高度依赖数据质量与激励设计，往往呈现"数据饥渴"；模型内部机制不透明，导致可解释性弱；在工况变化下的外推、以及长时滚动预测中的一致性与稳定性，均可能成为主要风险源。

灰箱（或混合）建模可被概括为：结构部分来自物理认知，未知部分或参数由数据辨识/学习补足。这一定义既覆盖"结构已定参数未知"的经典参数辨识，也覆盖"机理主干 +
学习残差"的现代混合建模形态。

一类典型灰箱是参数灰箱，即结构固定、参数由数据估计：
$$\dot{x}(t)=f\big(x(t),u(t);\theta\big),\qquad \hat{\theta}=\arg\min_{\theta}\,\mathcal{J}(\theta;Z).$$
与此相对，残差/补偿型灰箱更贴近复杂系统中的"机理不完备"现实，常写为
$$\dot{x}(t)=f_{\text{phy}}(x,u;\theta)+r_{\phi}(x,u),\qquad y(t)=g_{\text{phy}}(x,u)+h_{\phi}(x,u),$$
其中 $f_{\text{phy}},g_{\text{phy}}$ 为机理模型主干，$r_{\phi},h_{\phi}$
为由可学习模型（如神经网络）表示的未知项或未建模动态。该形式的关键优势在于：物理先验通过
$f_{\text{phy}}$
显式限定了学习空间，使得数据驱动部分只需补全不足，从而有望在数据效率、可解释性与鲁棒性之间获得更优折中。

进一步地，灰箱思想也可通过"引入辅助信息"的方式进入辨识流程。纯数据（仅
$Z$）作为黑箱辨识的唯一信息源，而将额外信息
$I$（如静态曲线、稳态数据、滞回特性或已知平衡点等）显式并入，则形成灰箱辨识框架：模型
$M$ 由数据集 $Z_N$ 与辅助信息 $I$
共同约束与确定。该观点强调：灰箱并不必然要求完整机理方程，任何可验证、可利用的先验信息都可作为结构性约束介入模型类选择、结构选择或参数约束，从而改善模型的动力学一致性。

综上，白盒---黑盒---灰盒谱系的关键不在于命名，而在于揭示了建模范式的内在张力：系统复杂性与非线性增强使纯机理模型难以覆盖全部动力学细节，数据驱动模型则以强表示能力弥补机理缺口，但同时带来可解释性与外推稳定性风险。近年来，人工智能方法推动系统辨识与建模发生结构性变化：一方面，数据驱动建模被系统化为可学习表示与端到端推断框架；另一方面，混合建模在结构上更强调机理约束下的学习，以提升复杂系统建模的精度与可靠性。

基于这一谱系视角，下一节将回到辨识实施层面，系统梳理典型系统辨识流程，并强调非线性背景下各环节的强耦合特征，从而为后续智能增强方法的引入建立清晰的工程与方法学落点。

### 系统辨识的基本流程

在明确了白箱、黑箱与灰箱等不同建模范式之后，有必要从流程层面对系统辨识的实施方式进行统一梳理。尽管不同建模范式在模型结构假设、物理先验占比以及数据依赖程度上存在显著差异，但其落地实施过程在宏观层面具有高度一致性。系统辨识正是在这一统一流程框架内，将建模假设、数据与算法有机结合，从而获得可用的动力学模型。

一般而言，无论采用机理驱动、数据驱动还是混合建模策略，一个典型的系统辨识问题通常包括以下几个基本环节：实验设计与激励选择、数据采集、数据预处理、模型类别与结构选择、参数或算子估计，以及模型验证与选择。这一流程已被广泛视为系统辨识领域的标准框架，在非线性系统辨识中同样适用，但各环节之间的耦合程度显著增强。

首先，实验方案与激励设计决定了数据中所蕴含的动态信息质量。对于动力系统而言，输入信号需在幅值与频谱上具有足够的激励能力，以确保系统的主要动态特性在观测数据中得到体现。随后进行的实验测试与数据采集阶段，则在既定实验条件下获取输入--输出或状态观测数据，为后续辨识提供原始信息基础。

在获得原始数据后，通常需要进行系统化的数据预处理。该阶段可能包括去噪、异常值处理、时间同步、重采样，以及在连续时间系统辨识中常见的数值微分或积分处理。其目的在于降低测量噪声与实验误差对辨识结果的干扰，并使数据形式与所选模型表达相匹配。需要指出的是，在非线性系统中，过度或不当的预处理可能引入额外偏差，因此该环节往往需要与后续模型验证反复迭代。

在此基础上，进入模型类别与结构选择阶段。这一阶段直接对应前文所讨论的"建模"问题：研究者需在连续/离散、确定/随机、输入--输出/状态空间等模型类别中作出选择，并进一步确定模型的结构形式，例如非线性项的构成、系统维数或基函数集合。这一环节直接体现前一节所讨论的建模范式差异：白箱建模中结构主要由物理机理给定；黑箱建模中结构由模型族与学习算法隐式决定；灰箱建模则在物理主干与数据驱动补偿之间进行组合。结构选择往往可形式化为在候选结构集合
$\{\mathcal{M}_1,\mathcal{M}_2,\ldots\}$
中进行筛选的问题，其结果将直接影响参数估计的可行性与模型泛化能力。

随后进行的参数或算子估计，是在既定模型结构下利用数据确定未知参数的过程。通常可表述为优化问题：
$$\hat{\theta}=\arg\min_{\theta}\;\mathcal{J}\big(y,\hat{y}(\theta)\big),$$
其中 $\hat{y}(k\mid \theta)$ 为模型在参数 $\theta$
下的预测输出。对于非参数或算子型模型，上式中的 $\theta$
可被推广为函数或算子集合。该阶段与结构选择并非完全独立，尤其在非线性系统中，参数估计结果常被用于反向评估结构合理性。

最后，模型验证与选择用于检验所得模型是否在统计意义和动力学意义上充分代表真实系统。验证方法不仅包括残差分析与预测误差评估，还可结合系统的动态不变量、稳定性特性或长期行为进行检验。若模型未通过验证，则需回溯前述步骤，对建模假设、结构选择或数据处理进行修正。

## 非线性系统数据驱动建模概述

### 数据驱动建模的概念

第一章从"建模---辨识"这一基本范式出发，系统讨论了模型作为真实系统的近似表达所不可避免的抽象与权衡，并在白箱---黑箱---灰箱谱系下进一步强调：当系统非线性增强、机理不完备与工况多变成为常态时，单纯依赖一阶原理的白箱建模往往难以在成本、精度与可部署性之间取得兼顾；与此同时，完全由经验设定模型类的传统黑箱辨识又容易受到数据质量、激励充分性与外推稳定性的制约。由此，围绕"如何在有限先验与有限数据条件下，获得兼具表达能力与可用性的非线性动力学模型"这一核心问题，数据驱动建模逐渐从传统黑箱辨识的技术集合，演化为更一般的建模范式。

从一般意义上看，"数据驱动"强调以数据作为主要信息来源与决策依据，其关注点不仅在于利用数据拟合一个映射函数，更在于围绕数据的获取、组织、清洗、建模与评估形成闭环流程，从而支撑可复用、可验证的知识提取与模型构建。对应到动力系统语境中，数据驱动建模可被理解为：在尽可能弱的结构先验假设下，以观测数据集
$Z$ 为主导信息源，借助统计学习与优化推断构造模型
$\mathcal{M}$，使其能够在预测误差、动态一致性以及任务相关指标（如控制性能或状态估计精度）等意义下有效表征系统行为。该范式与第一章所述系统辨识流程相一致，但其关键转变在于：模型结构不再由研究者完全预设，而是通过学习机制在"模型类选择---结构约束---参数估计"的耦合过程中逐步形成。

需要进一步区分的是，数据驱动建模与"黑箱建模"存在紧密关联但并不等同。黑箱建模通常指在缺乏可用机理结构时，直接以实验数据拟合输入--输出或状态演化映射，其模型内部机制相对不透明；而数据驱动建模作为范式更强调两点：其一，建模对象是"动力学过程"而非静态回归，因而必须关注滚动预测中的误差积累、稳定性与长期行为一致性等动力学特有问题；其二，数据驱动并不排斥先验信息，而是允许将可验证的结构性知识（例如守恒关系、平衡点、单调性、滞回特性或已知线性主干）以约束或正则的方式注入学习过程，从而在谱系上自然覆盖黑箱与灰箱/混合建模。换言之，数据驱动建模更接近于以数据为核心、以学习为手段、以泛化与一致性为目标的统一框架，其中黑箱模型是其重要特例，而物理约束下的学习模型则构成其向"智能增强"演化的关键路径。

在符号层面，数据驱动建模仍可沿用第一章的模型类---参数空间表述。设候选模型类为
$$\mathcal{M}_c={\mathcal{M}(\cdot;\theta)\mid \theta\in\Theta},$$

其中 $\theta$ 可取有限维参数向量，也可推广为函数/算子或神经网络权重。对离散时间动力系统，一类典型的数据驱动表述是直接学习状态演化与观测映射
$$x(k+1)=f_{\theta}\big(\Phi(k)\big),\qquad y(k)=g_{\theta}\big(\Phi(k)\big),$$
其中 $\Phi(k)$
表示由历史输入输出或状态构造的回归向量/特征映射。对应地，模型学习可统一写为经验风险最小化或统计推断问题：
$$\hat{\theta}=\arg\min_{\theta\in\Theta};\mathcal{J}\big(\mathcal{M}(\cdot;\theta),Z\big)+\lambda\,\mathcal{R}(\theta),$$
其中 $\mathcal{J}(\cdot)$ 描述数据拟合与预测误差，$\mathcal{R}(\cdot)$
则用于刻画复杂度、稀疏性或物理一致性等结构性偏好。该形式与第一章"结构---参数联合学习"的讨论保持一致，并为后续引入稀疏结构发现、深度序列模型、算子学习与物理约束学习等方法提供了统一的数学接口。

### 数据驱动建模方法：从线性到非线性

上一节从概念框架出发界定了"数据驱动建模"的内涵：以观测数据为主要信息源，在模型类选择、结构约束与参数学习的耦合过程中构造可用于预测、仿真与控制的动力学模型。在方法层面，这一范式最早在线性系统中形成了系统而成熟的技术体系（尤其是子空间辨识），并在面对强非线性、复杂噪声与部分可观测等现实约束时，进一步扩展为多类非线性数据驱动建模路线。因而，"从线性到非线性"的梳理不仅是模型形式的变化，更体现了建模目标从"拟合局部等效关系"向"学习可泛化的非线性动力学表示"的方法学转向。

#### 线性数据驱动建模：以 N4SID 为代表的子空间辨识

在线性时不变（LTI）假设下，离散时间状态空间模型可写为
$$x(k+1)=Ax(k)+Bu(k)+w(k),\qquad
    y(k)=Cx(k)+Du(k)+v(k),$$ 其中 $x(k)$ 为隐状态，$u(k)$ 为输入，$y(k)$
为输出，$w(k),v(k)$
分别为过程噪声与测量噪声。线性数据驱动建模的核心任务是：在仅给定输入--输出数据集
$Z=\{u(k),y(k)\}_{k=1}^{N}$ 的条件下，估计系统阶次并求得一组等价实现
$(A,B,C,D)$，从而得到可用于预测与控制的模型。其成熟方法体系通常可概括为三类主干并向若干方向扩展：其一为非参数方法，不预设显式结构而在时域以阶跃/脉冲响应、在频域以经验传递函数估计（ETFE）与谱分析等方式直接刻画动态特性，常用于建模前的快速诊断与验证；其二为以
Ljung
体系为代表的预测误差方法（PEM），在差分方程/多项式"黑箱"框架下通过最小化预测输出与实测输出的误差准则估计参数，典型模型包括计算高效且具解析最小二乘解的
ARX，以及进一步显式刻画噪声动力学、但需迭代求解并可能面临非凸局部极小的
ARMAX、OE 与 Box--Jenkins 等；其三为面向现代工业 MIMO
场景的子空间辨识（4SID），通过构造 Hankel
数据矩阵并利用投影与奇异值分解直接提取状态空间实现，在无需反复迭代的同时具备较好的数值稳定性与多变量适配性（如
N4SID、MOESP、CVA）。此外，为应对时变系统还可采用递推最小二乘与（双重）卡尔曼滤波等在线/自适应策略；为缓解高阶模型的过拟合与方差膨胀，可引入正则化/贝叶斯（核方法、高斯过程约束脉冲响应光滑性）以提升鲁棒性并降低对阶次精确设定的依赖。

以下我们以子空间辨识这一典型方法为例，介绍线性数据驱动建模的核心思想。子空间状态空间辨识以数值线性代数为基础，利用轨迹数据矩阵的低秩结构恢复状态子空间。其中，N4SID
是工程应用最为广泛的代表性算法之一，其典型做法可概括为：

1.  数据组织（矩阵化）：由输入--输出序列构造块 Hankel
    矩阵，并划分"过去/未来"数据块，使时间序列辨识转化为矩阵分解与子空间估计问题。

2.  投影与去噪：通过正交或斜投影在统计意义上抑制噪声影响，分离由输入激励解释的输出子空间成分。

3.  阶次估计与子空间提取：对投影矩阵进行奇异值分解，依据奇异值谱确定系统阶次，并获得扩展可观矩阵的估计。

4.  状态重构与参数回归：利用扩展可观矩阵重构状态序列，再以最小二乘获得
    $(A,B,C,D)$（必要时可进一步得到预测器形式及其增益）。

5.  模型验证与精炼：通过一步或多步预测误差、残差分析与交叉验证评估模型质量，并可在需要时引入基于预测误差的迭代精炼以提升统计效率。

从范式角度看，N4SID
的关键意义不止于提供一套线性辨识算法，更在于它清晰体现了线性数据驱动建模的基本逻辑：状态并非先验给定，而是从数据的子空间结构中涌现出来；动力学模型则是对该表示下演化算子与观测算子的估计。换言之，线性子空间方法实质上完成了两件事：

-   学习一个能够解释系统轨迹的潜在状态表示（以子空间形式隐式给出）；

-   在该表示上学习一个线性演化规律（矩阵 $A,B,C,D$ 的估计）。

这一思想为非线性数据驱动建模提供了直接的延伸方向：当系统不再满足线性叠加时，方法的核心转化为如何构造或学习一种合适的非线性表示，使得系统演化在该表示下仍可被有效估计与泛化。因此，非线性方法可以被理解为对"表示---演化"这一核心链条的不同实现策略。

#### 从线性到非线性：线性方法的边界与扩展动因

在许多工程系统中，系统往往在高性能或极端工况下呈现显著非线性。此时，线性模型的典型作用是提供工作点附近的等效近似或作为基线模型，但其局限也较为明确：非线性失真会导致线性模型在多步滚动预测中误差累积，甚至出现自由运行不稳定；复杂噪声结构与激励不足会放大辨识偏差，并造成拟合良好但动力学行为失真的风险；非线性现象（多稳态、分岔、滞回、强耦合等）往往无法被线性结构显式表达，从而限制模型的可解释性与可外推性。

因此，线性到非线性的扩展通常遵循两条互补主线：

1.  结构化扩展：保留一定机理可解释性，通过受控的非线性结构假设降低问题难度；

2.  一般表示学习：弱化结构先验，以更强的函数表示能力直接学习非线性演化规律，并在验证阶段强调泛化、稳定性与可部署性。

我们将这些方法大致分为五大类：经典参数化方法、块结构/混合模型方法、可解释学习方法、算子与变换理论方法和基于智能技术的方法。接下来我们会逐一展开详细介绍。

#### 非线性数据驱动建模：经典参数化与基函数展开法

在上一节从线性子空间辨识过渡至非线性建模时，核心问题已由"线性系统的阶次与矩阵估计"转向"非线性表达的选择与结构确定"。经典参数化与基函数展开法正是在这一语境下形成的代表性路线：其基本思想是以预设的函数级数或基函数族作为非线性表达载体，将非线性系统映射为有限维参数估计与结构选择问题，从而在可解释性与可计算性之间取得折中。该类方法理论体系成熟，尤其适用于具有较强光滑性、弱非线性或有限记忆特征的对象，并在工程振动与信号处理等领域长期占据重要地位。

Volterra
级数可视为线性卷积模型的自然推广：线性时不变系统由冲激响应唯一刻画，而
Volterra
级数通过高阶卷积核描述非线性与记忆效应的耦合，从而在输入--输出层面对广泛非线性动态给出统一表示。其连续时间形式常写为
$$y(t)=\sum_{n=1}^{\infty} H_n[u](t),$$
其中 $H_n$ 为 $n$ 阶 Volterra
算子，对应的 $n$
维核函数是线性冲激响应的非线性推广；在频域中，核的傅里叶变换常对应高阶频响函数，使得
Volterra 表达能够与频域辨识框架衔接。

在工程辨识中，Volterra
方法的关键挑战并非概念层面的统一性，而是实现层面的维数灾难：核函数的参数规模随阶数与记忆长度呈爆炸式增长，高维系统下尤为突出，直接限制了其在强非线性与高维对象中的可用性。为缓解参数规模问题，相关研究往往引入正交基对核进行结构化展开，或在特定频段内进行辨识以降低计算负担；但总体而言，Volterra
仍更适合作为弱非线性与有限记忆系统的结构化建模工具，而非高维强非线性的通用方案。

与 Volterra 强调高阶核卷积不同，NARMAX
将非线性系统辨识转化为离散时间域上的非线性回归问题：系统输出由历史输出、历史输入以及噪声（预测误差）项的非线性函数决定。其一般形式可写为
$$y(k)=f\big(y(k-1{:}k-n_y),u(k-d{:}k-n_u),e(k-1{:}k-n_e)\big)+e(k),$$
其中 $n_y,n_u,n_e$ 为滞后阶次，$d$ 为输入延迟，$e(k)$
为创新噪声。该框架的核心优势在于：一旦给定函数族与候选项集合，辨识即可落到可实现的结构选择与参数估计流程，并可通过线性
ARX 或 ARMAX 作为特例自然衔接线性辨识体系。

需要强调的是，NARMAX
的难点主要集中在结构选择：候选项集合往往规模庞大，冗余或错误项不仅导致过拟合，更可能引入显著的虚假动力学行为，从而在自由运行仿真与长时域预测中表现为不稳定或偏差累积。因此，NARMAX
在方法论上通常与逐步项选择与正交最小二乘类策略耦合使用，例如正交前向回归与误差缩减率准则等；同时也不断发展面向泛化与仿真稳定性的改进结构选择机制。

NARMAX 的常见变体包括：去除噪声项得到 NARX，去除输入项得到 NAR。

为突出数据驱动建模如何落地，以下以多项式或基函数型 NARX 与 NARMAX
为例，给出较为标准且可复用的辨识流程。该流程与模型类、结构、参数与验证的概念框架保持一致，但在非线性情形下，结构选择与验证环节的重要性显著上升。

NARX 模型通常写为 $$y(k)=F\big(\varphi(k)\big)+e(k),\qquad
    \varphi(k)=\big[y(k-1{:}k-n_y),u(k-d{:}k-n_u)\big],$$ 其中
$\varphi(k)$
是由历史输入与输出构成的回归向量。若采用多项式或一般基函数展开，可进一步构造候选函数库
$$\Theta(\varphi)=\big[\theta_1(\varphi),\theta_2(\varphi),\ldots,\theta_M(\varphi)\big],$$
从而得到线性参数化形式 $$y(k)\approx \Theta(\varphi(k))\,\xi+e(k),$$
其中 $\xi$
为待估参数向量。该步骤体现了经典路线的核心特征：通过预设基函数族把非线性映射变为结构化的线性回归问题，使后续可用最小二乘与统计检验工具实施辨识。

当引入噪声模型时，NARMAX
在回归向量中加入预测误差滞后项，从而能够更系统地描述测量噪声与未建模动态对输出的影响；但与此同时，误差项不可直接观测，使得估计过程通常需要迭代或在预测误差框架下联合优化。在多项式
NARX 或 NARMAX
中，候选项库通常由线性滞后项、输入输出交叉项以及高阶非线性项组成。库的规模由滞后阶次与最高阶数共同决定，往往迅速增长，并直接导致结构选择复杂度上升。实践中，候选库设计需要遵循可表达但不过宽的原则。面对大规模候选库，经典做法是采用正交前向回归进行逐步选项：算法在正交化的回归空间中评估每个候选项对输出的独立贡献，并按准则逐次纳入模型。采用误差缩减率准则时，策略是在有限项数下尽可能解释输出方差。然而，基于误差缩减率的传统方法往往在一步预测意义下优化拟合，可能选入冗余或错误项，导致过拟合，并在长时域自由运行预测中出现不稳定性。近年来的改进路线包括将迭代正交前向回归与近似交叉验证统计量结合，并引入基于仿真的稳定性筛选与信息准则进行模型选择。

在结构确定后，参数估计通常采用最小二乘或加权最小二乘方法。对于
NARMAX，由于噪声模型引入不可观测的误差序列，实践中常采用迭代式估计或预测误差框架以获得一致估计。

非线性输入--输出模型的验证应至少覆盖一步预测误差、多步预测误差以及自由运行仿真误差。仅在一步预测意义下最优的结构，往往无法保证自由运行的稳定与可信。尽管
NARX 与 NARMAX
在形式上是纯数据驱动的，但其可辨识性强烈依赖输入是否提供足够激励。实践中常使用具有宽频谱特性的激励信号，以避免结构选择陷入仅拟合局部被激发动力学的次优解。

总之，经典参数化与基函数展开法通过基函数库、结构选择、参数估计与动力学验证的闭环，将非线性建模问题转化为可实现的统计估计与模型选择任务。其优势在于模型形式显式、可解释性强且便于工程实现；其局限在于候选库膨胀与结构选择偏差对长时域一致性的敏感性。面向更高维、更强非线性与更复杂观测条件时，通常需要引入更一般的学习型表示及约束注入机制。

#### 非线性数据驱动建模：块结构模型

在经典参数化与基函数展开方法之外，另一条在工程界更"可落地"的非线性建模路线，是块结构模型（block-oriented
models）。该类方法不再试图用单一的全局非线性映射直接覆盖全部动力学，而是引入明确的结构假设：系统可由线性动态环节（Linear
dynamic block，记为 $L$）与静态非线性环节（Static nonlinearity，记为
$N$）通过串联或并联方式组合而成。由于该结构能够将许多工程非线性（如执行器死区/饱和、传感器非线性等）以可解释的形式"定位"到特定环节中，块结构模型通常被视为典型的灰箱建模范式，并在工业过程与机电系统辨识中具有长期应用基础。

从建模角度看，块结构假设的作用相当于对非线性模型类施加强结构先验：它显式限定非线性的"发生位置"（输入侧或输出侧）与"类型"（静态、无记忆），从而显著降低结构搜索空间与参数耦合程度。也正因如此，该类方法与前述
NARX/NARMAX
等全局回归模型相比，往往在数据效率、可解释性与工程部署性方面更具优势，但其适用性也受限于结构假设是否与真实系统机理相符。

为便于统一描述，以下以离散时间形式表述块结构模型。设
$G(q^{-1};\theta_L)$ 表示线性动态环节（可取传递函数、ARX/ARMAX
或状态空间参数化）， $N(\cdot;\theta_N)$
表示静态非线性映射（如多项式、分段线性、饱和/死区模型、样条等）。则典型块结构可归纳为：

1.  Hammerstein（N--L）： $$v(k)=N\big(u(k);\theta_N\big),\qquad
            y(k)=G(q^{-1};\theta_L)\,v(k)+e(k).$$

2.  Wiener（L--N）： $$x(k)=G(q^{-1};\theta_L)\,u(k),\qquad
            y(k)=N\big(x(k);\theta_N\big)+e(k).$$

3.  级联扩展（如 Wiener--Hammerstein 或 Hammerstein--Wiener）：
    $$x(k)=G_1(q^{-1})u(k),\quad
            v(k)=N(x(k)),\quad
            y(k)=G_2(q^{-1})v(k)+e(k),$$
    以及在输入侧与输出侧同时存在静态非线性的 $N$--$L$--$N$ 等变体。

其中噪声 $e(k)$
可被视为测量噪声与未建模动态的综合项；在更严格的系统辨识语境中，也可进一步对噪声进行显式建模并引入预测误差框架，但块结构建模的首要困难通常仍是结构与参数的耦合估计，而非噪声形式本身。

Hammerstein
模型将静态非线性置于输入侧，随后串联线性动态环节。其工程含义较为直接：许多控制系统的主要非线性来源于执行器或输入通道（如死区、饱和、摩擦导致的等效非线性增益等），而系统本体在一定工作域内仍可用线性动力学较好表征。Aguirre
在讨论非线性模型类时将 Hammerstein
视为典型的块结构模型，并给出了带死区型静态非线性的示例构造，体现了该结构对"非光滑静态特性"的自然表达能力。

从"如何数据驱动"的角度，Hammerstein 辨识通常可分解为两类子问题：

1.  静态非线性 $N$
    的估计：利用输入幅值变化所激发的静态映射特性，在选定参数化形式后估计
    $\theta_N$。常见做法包括：

    1.  选择物理含义明确的非线性（死区、饱和、分段线性等）并进行参数回归；

    2.  采用基函数展开（多项式/样条等）逼近静态映射，以便与最小二乘或正则化回归兼容。

2.  线性动态 $G$ 的估计：在获得 $$v(k)=N(u(k))$$
    的"等效输入"后，线性块可用标准线性辨识工具估计（如
    ARX、子空间方法、预测误差法等）。这一点体现了块结构模型的重要优势：通过结构分解，使得线性理论工具仍可在非线性系统辨识中发挥核心作用。

需要强调的是，上述分解在实现上并非总能"一步到位"，原因在于 $N$ 与 $G$
的估计存在耦合：若 $N$
初值偏差较大，会将系统动态误差"折算"为静态映射误差，进而影响线性块估计。实践中常采用两阶段初始化加迭代精化的策略：先用线性近似或简化非线性获得可用初值，再在联合目标（如预测误差）下交替更新
$\theta_N$ 与
$\theta_L$。块结构假设的价值，正体现在它为这种可控的迭代提供了结构坐标系，而不必在过于宽泛的全局非线性模型类中盲目搜索。

与 Hammerstein 相对，Wiener
模型将线性动态置于前端，静态非线性位于输出侧。其典型应用场景是：系统内部动态链条可近似为线性，但测量环节或传感器存在显著非线性（如量程饱和、非线性标定曲线等），导致观测输出
$y(k)$ 与内部线性状态或中间变量 $x(k)$ 呈非线性关系。

Wiener 辨识的关键困难通常在于：中间变量 $$x(k)=G(q^{-1})u(k)$$
不可直接观测，而静态非线性 $N$
的输入正是该不可观测量。为此，数据驱动辨识往往采取以下典型路径：

1.  线性近似初始化：先忽略输出非线性，在"最佳线性近似"意义下估计 $G$
    的初值；随后用该线性块生成 $\hat{x}(k)$，再据此拟合 $N(\cdot)$。

2.  联合优化或迭代预测误差法：将 Wiener 系统视为由 $\theta_L$ 与
    $\theta_N$
    共同决定的非线性预测模型，最小化预测误差并迭代更新参数，从而缓解误差在
    $\hat{x}(k)$ 中传播导致的偏差累积。

这类"从线性近似出发"的思路在块结构系统辨识中具有普遍性，并已形成专门综述与方法体系。其本质原因在于：块结构模型虽引入非线性，但仍保留了可利用的线性骨架，使得线性辨识可作为稳定、可解释的初始化手段。

当系统同时存在输入侧与输出侧非线性，或需要在静态非线性前后各保留一段线性动态以刻画不同频段或不同机理的动态特征时，常采用更一般的级联结构，如
$L$--$N$--$L$（Wiener--Hammerstein）或
$N$--$L$--$N$（Hammerstein--Wiener）。该类结构在表达能力上显著强于单块模型，但代价是参数耦合更强、可辨识性更敏感，尤其在噪声条件下容易出现多解与局部最优。

在工程应用中，级联块结构并非停留在理论层面。例如，在结构动力学与损伤检测语境下，已有工作采用
Hammerstein
模型级联构造非线性识别链条，用以增强对局部非线性的表征能力。另一方面，在更一般的非线性动力学辨识问题中，Wiener--Hammerstein
等结构也经常与全局优化或启发式搜索结合，以同时估计线性块阶次与非线性参数；但此时线性块稳定性约束往往成为不可忽略的工程要点，否则搜索过程会产生大量不稳定候选模型并造成计算资源浪费。

因此，在学术叙述上应明确：级联块结构的引入是以牺牲部分辨识难度为代价换取表达能力提升，其成功实施通常依赖更强的先验约束、更精细的激励设计以及更严格的验证机制。

综合上述模型形态，块结构模型的"数据驱动"并不意味着完全端到端的黑箱拟合，而是遵循一种更具工程可控性的流程：在结构先验约束下，用数据估计结构内部的有限维参数。其典型实施要点可概括为：

1.  结构假设与参数化选择：明确采用 $N$--$L$、$L$--$N$ 或 $L$--$N$--$L$
    等结构，并为 $G(\cdot)$、$N(\cdot)$
    选择可估计的参数化形式（ARX、状态空间；多项式、样条、分段线性、饱和死区等）。块结构模型被视为重要非线性模型类，正是由于其在"可表达---可估计---可解释"之间提供了相对稳健的折中。

2.  线性近似初始化：在不完全忽略非线性的前提下，先获得合理的线性动态初值（例如基于线性辨识得到的近似
    $G_0$），再据此生成中间变量并拟合静态非线性。块结构系统"从线性近似起步"的辨识路线已形成系统性综述。

3.  两阶段与迭代联合估计：

    1.  两阶段：先固定 $N$ 估计 $G$，或先固定 $G$ 估计 $N$；

    2.  迭代联合：在预测误差准则下交替或联合更新 $\theta_L$ 与
        $\theta_N$，以降低估计偏差并提升自由运行一致性。

4.  激励设计与可辨识性约束：静态非线性参数的可靠估计要求输入在幅值域具有足够覆盖，而线性动态估计要求频域激励充分。若输入激励不足，非线性效应可能被"吸收"为线性块参数偏差或噪声项，从而破坏结构分解的物理含义。

5.  验证指标的层次化：除一步预测误差外，应关注多步预测与自由运行仿真一致性，并结合残差检验评估是否存在未被块结构捕捉的动态非线性（如滞回、速率相关非线性等）。当验证显示"静态非线性加线性动态"的结构不足以解释数据时，应回退并考虑更一般的模型类（例如引入动态非线性块、并联系统，或转向下一类更通用的方法框架）。

块结构模型通过将非线性"定位"为静态环节，并保留线性动力学骨架，使得非线性系统建模能够在较强可解释性与工程可实现性下开展，因此成为工业界广泛采用的灰箱方法家族。其边界同样清晰：当系统非线性具有显著动态记忆（如滞回、摩擦预滑、速率相关效应）或呈现强耦合高维特征时，简单的
$N$--$L$ 或 $L$--$N$
结构往往难以充分描述，需要引入更一般的非线性建模框架。

#### 非线性数据驱动建模：稀疏辨识与符号回归

与前述"经典参数化与基函数展开法"相比，稀疏辨识与符号回归更强调从数据中反推出具有显式解析形式的动力学方程，即在"拟合---预测"之外，进一步追求对系统机理结构的可读表达与可解释参数。这一方向近年来受到广泛关注，其方法论动机可概括为两点：其一，传统高阶多项式或级数展开在候选项规模增大时容易出现结构冗余与过参数化，进而引入虚假动力学、降低仿真稳定性与外推可信度；其二，在工程与科学计算场景中，研究者往往希望模型不仅能用，还应当可解释、可验证、可用于分析与控制。前者的风险在非线性系统辨识中已被反复讨论，例如过参数化可能导致模型在自由运行预测（simulation）中明显失真，并对结构选择提出更高要求。

该类方法可粗分为两支：一支以 SINDy（Sparse Identification of Nonlinear
Dynamics）为代表，采用"候选函数库加稀疏回归"的形式实现结构发现；另一支以更一般的符号回归（symbolic
regression）为代表，通过搜索或进化策略在表达式空间中直接生成可解释方程。二者共同特点是：模型结构以显式数学表达给出，便于进行物理解释、稳定性分析与结构约束检验；区别在于，SINDy
将结构发现转化为稀疏优化问题，计算路径更为明确，而符号回归的搜索空间更开放，表达力更强但代价通常更高。以下我们以
SINDy 为典型代表展开详细介绍：

SINDy
的核心假设是：尽管非线性系统的动力学函数形式可能复杂，但在一个合理的候选函数集合中，真实系统的动力学通常只依赖其中少数几个关键项，即参数向量在该候选库上是稀疏的。以连续时间自主系统为例，
$$\dot{x}(t)=f(x(t)),$$
SINDy
通过构造一个由候选非线性函数组成的字典或函数库
$$\Theta(X)=\big[\theta_1(X),\theta_2(X),\ldots,\theta_p(X)\big],$$
并将动力学在该库上展开为线性组合： $$\dot{X}=\Theta(X)\Xi,$$
其中
$$X=[x(t_1),\ldots,x(t_N)]^\top,$$
$\dot{X}$ 为对应的状态导数数据，$\Xi$
为待求的稀疏系数矩阵。其典型优化形式可写为（以列向量形式表述每个状态分量的回归）：
$$\min_{\Xi}\ \|\dot{X}-\Theta(X)\Xi\|_2^2+\lambda\|\Xi\|_1,$$
或采用顺序阈值最小二乘（STLSQ）等策略，在"最小二乘拟合、阈值剪枝、再拟合"的迭代中得到稀疏解。该过程的结果是：模型结构以少数非零系数对应的库函数项显式给出，从而实现对动力学方程的可读发现。

需要强调的是，SINDy
与第一类"经典参数化与基函数展开法"在形式上都包含"基函数或候选项"的概念，但二者的目标函数与输出语义存在实质差异。经典
NARX 或 NARMAX
往往在庞大的候选项集合中进行结构筛选，重点是获得预测性能良好的输入输出映射；SINDy
则将结构稀疏作为核心先验，将问题显式转化为稀疏优化，从而更直接地抑制冗余项与过参数化风险。过度复杂结构可能引入虚假动力学并削弱自由运行预测稳定性，这类风险在非线性辨识实践中已被广泛指出。参数解释更贴近物理机制。当候选库按物理启发构造（例如包含
$x$、$x^3$、$\dot{x}$、$x\dot{x}$
等项）时，非零系数可直接对应具体的非线性机制强度。例如在 Duffing
型非线性振子中，若库中包含 $x^3$
项，则其系数可自然解释为三次非线性刚度强度，常记作 $k_3$
或等效系数；这使得模型不仅可用于预测，还可用于机理量化、参数对比与结构诊断。更易引入结构性约束与验证。由于输出模型为显式方程，研究者可以将守恒关系、对称性、维度一致性、稳定性条件等作为结构性检验标准，反向约束候选库与稀疏解的合理性；这在需要可解释、可验证、可复现的科学发现任务中尤为关键。

最后，从第一章所述辨识流程视角看，SINDy
仍遵循"数据、特征、估计、验证"的基本链条，但其关键环节具有更强的结构导向性，可概括为以下步骤：

1.  数据采集与状态重构。在能够获得状态 $x(t)$
    的场景（或通过观测重构得到近似状态）下，形成样本矩阵
    $X$。若系统含控制输入，则扩展为 $$\dot{x}=f(x,u),$$ 并在库中引入 $u$
    及其交叉项以刻画输入作用。

2.  导数估计（连续时间场景的关键难点）。SINDy 的基本形式需要
    $\dot{X}$。但数值微分对噪声高度敏感，因此通常需要平滑滤波、样条拟合、全变分正则化等稳健导数估计手段；或改用积分或弱形式以降低微分放大噪声的问题。该环节本质上与病态或不适定问题的正则化处理密切相关。

3.  候选函数库构造（$\Theta(\cdot)$
    的设计）。库函数可取多项式、三角函数、径向基、分段函数等。库越丰富表达力越强，但计算与结构歧义也越大；库越受限，稀疏解越稳健但可能出现欠表达。工程上常采用"物理启发的库加逐步扩展"的策略，以减少无意义项带来的结构漂移风险。

4.  稀疏回归求解与超参数选择。通过 $\ell_1$
    正则、阈值迭代或其他稀疏促发机制得到 $\Xi$。阈值或正则权重 $\lambda$
    控制"拟合误差与结构复杂度"的折中，本质上对应第一章所述的结构与参数联合学习思想，只是此处结构稀疏性成为主导正则。

5.  模型验证：短期预测与长期动力学一致性并重。除常规一步预测误差外，SINDy
    更应强调自由运行仿真、相空间结构、稳态或极限环等动力学性质的一致性检验；因为稀疏模型往往用于解释与外推，其有效性应体现为对关键动力学特征的可复现性，而不仅是局部拟合优度。

#### 非线性数据驱动建模：算子理论与变换方法

与前述"直接在原状态空间中构造非线性映射"的参数化方法不同，算子理论与变换类方法的核心思想是：不显式拟合复杂非线性项本身，而是通过"升维/变换"将非线性动力学等价（或近似）表示为线性演化，从而把线性系统理论中成熟的分析与控制工具（如稳定性分析、LQR、MPC
等）迁移到非线性系统场景。这类方法在方法论上与第一章的"模型类选择决定辨识搜索空间"一脉相承：其建模假设不在于选择某一类非线性基函数，而在于选择一种线性化语境------要么在可观测函数空间中引入线性算子（Koopman/DMD），要么将系统视为参数调度下的线性系统族（LPV）。

对一般非线性离散系统 $$x_{k+1}=f(x_k),$$ 尽管状态 $x_k$
的演化是非线性的，但若考虑一组可观测量（observables）$\psi(x)$（可为状态的非线性变换、物理可测特征或其组合），则存在作用于可观测函数空间的线性算子
$\mathcal{K}$（Koopman 算子），使得
$$\psi(x_{k+1})=\mathcal{K}\psi(x_k).$$
Koopman
理论的关键在于：$\mathcal{K}$
在严格意义下通常是无限维线性算子；因此工程应用采用有限维近似，其代表实现即动态模态分解（DMD）及其扩展形式（如
EDMD）。

数据驱动实现路径通常可概括为"数据快照---升维---线性回归---谱分解"四步：

1.  采集快照对：从观测序列构造 $$X=\big[x_1,x_2,\ldots,x_m\big],\qquad
            X'=\big[x_2,x_3,\ldots,x_{m+1}\big].$$

2.  选择或构造可观测映射：给定特征映射 $\psi(\cdot)$，形成
    $$\Psi(X)=\big[\psi(x_1),\ldots,\psi(x_m)\big],\qquad
            \Psi(X')=\big[\psi(x_2),\ldots,\psi(x_{m+1})\big].$$

3.  线性算子近似（回归估计）：通过最小二乘估计有限维线性算子 $A$
    $$A=\arg\min_{A}\ \|\Psi(X')-A\Psi(X)\|_F^2,$$
    使得在升维空间中满足近似线性递推
    $$\psi(x_{k+1})\approx A\psi(x_k).$$

4.  谱分解与动态模态：对 $A$ 做特征分解或 Schur
    分解得到特征值与模态，从而构造可解释的"增长或衰减率---振荡频率---空间结构"表征，并用于预测与降阶。

在此框架下，DMD 可视为最基本的 Koopman
近似：当可观测量取为恒等映射（或线性观测）时，回归得到的 $A$
直接对应对原始状态或观测的线性拟合；当引入更丰富的 $\psi(\cdot)$
时，则得到对 Koopman 算子的更强表达近似（常称 EDMD
思路）。进一步地，若系统包含输入 $u_k$，可通过带控制项的线性回归（如将
$\psi(x_k)$ 与 $u_k$
一并作为回归变量）获得可用于控制设计的线性预测模型，其本质仍是将非线性影响吸收进升维表示与线性算子中。

该类方法的优势在于结构上"线性化"，便于与线性控制与估计体系耦合；其主要挑战在于可观测量选择决定了线性化近似质量：可观测量过弱会导致模型欠拟合，可观测量过强则引入高维回归与噪声敏感性。关于"如何更系统地构造或学习可观测量"的问题，往往会自然过渡到后续的智能增强路线；但在本节中，仅将其作为算子方法的关键前提加以指出。

与 Koopman 的"升维线性化"不同，线性参数变化（LPV, Linear Parameter
Varying）采取另一种工程化的线性化路径：假设系统在给定调度参数（scheduling
parameter）$\rho(t)$ 下可表示为线性系统，但系统矩阵随 $\rho$ 平滑变化：
$$\dot{x}(t)=A(\rho(t))x(t)+B(\rho(t))u(t),\qquad
    y(t)=C(\rho(t))x(t)+D(\rho(t))u(t).$$ 其中 $\rho(t)$
通常为可测的工况变量（如速度、攻角、载荷、温度等）或由可测量构造的调度量。该范式在航空航天与汽车等领域具有长期的工程实践基础，原因在于其在"非线性表达能力"与"线性控制可用性"之间提供了可操作折中：系统允许非线性随工况变化而体现，但在任一瞬时仍保持线性结构，便于应用增益调度与鲁棒控制框架。

数据驱动实现方式通常有两条主线，均体现"在结构约束下用数据估计随参数变化的线性模型"：

1.  局部线性模型辨识加插值或拼接。在若干代表性工况点 $\rho=\rho_i$
    附近采集数据，分别辨识得到一组 LTI 模型
    $(A_i,B_i,C_i,D_i)$。随后通过插值、加权或分段调度构造
    $A(\rho),B(\rho)$
    等。该路线实现直观、工程落地性强，但对工况覆盖与数据分布较敏感，且模型拼接的平滑性与一致性需要额外处理。

2.  全局参数化表示加统一回归估计。预先指定矩阵函数对 $\rho$
    的依赖形式，例如仿射、多项式或基函数展开：
    $$A(\rho)=\sum_{j=1}^{r}\alpha_j(\rho)A^{(j)},\qquad
            B(\rho)=\sum_{j=1}^{r}\alpha_j(\rho)B^{(j)},$$ 其中
    $\alpha_j(\rho)$ 为已知的基函数，未知系数矩阵 $A^{(j)},B^{(j)}$
    由数据通过最小二乘、极大似然或约束优化估计得到。该路线更便于保证模型整体一致性，但要求对
    $\rho$
    的选择与基函数族有合理先验，并需要足够覆盖调度空间的激励数据。

LPV 的有效性高度依赖两个前提：其一，$\rho(t)$
必须能够充分表征非线性随工况变化的主导因素；其二，数据采集需要在调度空间内提供足够激励，以避免在某些
$\rho$ 区域模型不可辨。因此，LPV
更适用于"非线性主要由工况变化引起、且调度变量可测或可构造"的系统；对于强内禀非线性、难以用低维调度量描述的现象，LPV
可能需要更高维的调度或更复杂的分区策略，从而削弱其工程优势。

#### 非线性数据驱动建模：基于智能技术的数据驱动建模方法

在前述几类方法中，无论是基函数展开、块结构假设、稀疏辨识还是算子线性化，其共同特征是：模型结构在形式上相对显式，辨识过程可归结为结构选择与参数估计。与之相对，基于智能技术的数据驱动建模更倾向于采用高容量的可学习函数族（神经网络与概率非参数模型等）直接近似非线性动力学映射，从而在高维、强非线性、强耦合与部分可观测等场景下获得更强的表示能力与预测性能。该类方法通常具有黑箱特征：结构更多由网络架构与训练机制隐式决定，辨识则表现为端到端的参数学习过程。

常见代表可概括如下：

1.  循环神经网络及其变体（RNN/LSTM/GRU）：通过递推隐藏状态刻画时序依赖关系，适合用于动态系统的序列建模与多步预测，尤其在存在长时间依赖或多尺度演化时更具优势。

2.  储备池计算（ESN/Reservoir
    Computing）：利用固定或弱调参的高维动态储备池生成丰富时序特征，仅训练读出层参数，因训练成本低、实现简洁而常用于快速建模与在线更新场景。

3.  神经微分方程（Neural
    ODE）：以连续时间导数参数化为核心，适配连续时间系统与非均匀采样数据，为后续将物理约束更自然地融入学习框架提供接口。

4.  物理信息神经网络（PINNs）：将物理方程及其边界或初值条件以正则化或约束方式纳入损失函数，以提升小样本条件下的可解释性与外推能力。

5.  高斯过程回归（GP）：以贝叶斯非参数方式给出预测分布与不确定性量化，适合小样本与安全关键场景下的建模与决策支持。

需要指出的是，本类方法的核心价值并不只是更强拟合，而在于其提供了可学习的表示与推断框架，使得模型能够在更弱的人工结构设定下吸收复杂非线性与高维耦合效应；与此同时，它也带来结构不透明、外推鲁棒性与长期动力学一致性评估等新问题。由于这些问题与智能增强建模的主题高度耦合，且需要专门讨论其训练机制、约束注入与可解释性提升路径，本文在本节仅作谱系式概述，并将在下一章对相关方法与关键技术环节进行集中展开。

## 基于智能技术的数据驱动建模方法

### 智能技术概述

在非线性系统数据驱动建模中，"智能技术"可被理解为一类以自适应机制为核心、能够在复杂与变化环境中实现学习、搜索与优化的算法方法族，其典型代表集中于计算智能（computational
intelligence, CI）框架之下。按照 Quaranta
等（2020）的界定，计算智能作为人工智能的重要组成，关注通过可计算的自适应机制促成智能行为，尤其适用于非线性系统辨识中普遍存在的非凸、强耦合与不确定性情形。

为避免"智能技术"概念外延过宽而削弱方法论指向，本章在综述层面将其限定于计算智能谱系，并采用
Quaranta 等（2020）所强调的三类关键构成来组织后续讨论，即：

1.  演化计算（evolutionary
    computing）：以自然选择与遗传演化为原型的群体式搜索机制，典型算法包括遗传算法（GA）与差分进化（DE）；在结构发现层面，遗传编程（GP）亦常被纳入该范畴。

2.  群智能（swarm
    intelligence）：以群体协同行为为启发的分布式搜索机制，本文重点对应粒子群优化（PSO）。

3.  神经计算（neurocomputing）：以人工神经网络（ANN）为代表的学习型逼近机制，用于直接构造输入---输出或状态演化映射。

这一分类方式的关键价值在于：它并非仅以"算法清单"罗列技术，而是以机制层面的共同结构（群体搜索、协同更新、可学习逼近）来解释这些方法何以在非线性辨识中有效，从而为后续"算法---任务---模型形式"的对应关系提供统一语义基础。

计算智能方法之所以能够进入系统辨识的核心流程，根本原因在于：大量辨识任务可被统一表述为以模型误差（或差异度量）为目标的优化或搜索问题。Quaranta
等（2020）在参数辨识脉络下给出了典型形式：设待估参数向量为
$x$，模型输出为 $y(x)$，实验或观测响应为 $\hat{y}$，则可构造差异度量
$g(\cdot)$，并形成约束优化问题 $$\min_{x}\ f(x)=g\big(\hat{y},y(x)\big),
    \qquad \text{s.t.}\quad x^{\min}\le x \le x^{\max}.$$
其中，$g(\cdot)$
可对应时间域误差、频域差异或其他统计意义下的距离；而区间约束反映了工程先验（物理可行范围、稳定性边界、结构尺寸或材料参数界等）。

需要强调的是，这一表述不仅适用于"结构已定、参数未知"的参数辨识，也为"结构与表达待定"的非参数辨识或模型发现提供了抽象接口：差异度量仍是核心，但搜索对象从有限维参数扩展为模型结构与函数表达本身。也正因为搜索空间的性质发生变化，计算智能内部不同分支在辨识中的角色随之分化：演化计算与群智能更偏向"搜索与全局寻优"，神经计算更偏向"可学习函数逼近"，遗传编程则位于二者之间，承担"结构生成与表达式搜索"的功能定位（Quaranta
et al., 2020）。

在概念框架上，Quaranta
等（2020）将方法组织为参数化（parametric）与非参数化（nonparametric）两类辨识任务导向：

1.  参数辨识（parametric
    identification）：模型结构（例如某类振子模型、有限自由度动力学方程、预设的本构或阻尼形式等）被预先指定；辨识的核心是寻找最优参数
    $x$
    以最小化模型与数据之间的差异。此时，计算智能方法通常作为优化器嵌入辨识流程，用于在复杂误差地形中寻优（Quaranta
    et al., 2020）。

2.  非参数辨识（nonparametric
    identification）：不再把结构完全固定为给定形式，而是将目标提升为"在某个模型空间中寻找能够解释数据的数学模型"。在这一语境下，搜索对象可能是函数结构、表达式树、网络映射或其组合；相应地，计算智能方法不仅用于参数更新，也可能直接参与结构生成与选择（Quaranta
    et al., 2020）。

这一划分的意义在于：它把"智能技术"的贡献从单纯的数值优化提升到更一般的模型生成机制，从而与第二章所讨论的"结构---参数耦合学习"形成明确的概念衔接。

#### 演化计算：以群体演化实现参数寻优与结构生成

演化计算的核心概念是：以候选解群体为载体，通过模拟遗传与选择机制实现迭代改进。Quaranta
等（2020）在其综述范围内重点涉及三类代表性实现，它们在"搜索对象"与"输出语义"上存在层次差异。

1.  遗传算法（GA）：选择、交叉与变异驱动的群体搜索。 GA
    将待辨识对象编码为个体（解向量或编码串），并通过适应度（由 $f(x)$
    或其变体给出）评估个体优劣；随后以选择算子保留高适应度个体，以交叉与变异产生新个体，从而在迭代中实现群体改进。其概念优势在于：当误差函数来源于复杂动力学仿真、具有多峰性或存在不规则性时，GA
    仍可在无需显式解析梯度结构的条件下推进搜索（Quaranta et al.,
    2020）。

2.  差分进化（DE）：基于差分扰动的向量进化机制。 DE
    同样属于群体式随机搜索，但其核心特征在于：利用群体中个体差分构造扰动并生成候选向量，再通过选择保留更优者，从而实现迭代更新。概念上，DE
    将群体分布信息直接转化为更新方向与尺度，因而在连续参数空间寻优场景中具有明确的方法学定位（Quaranta
    et al., 2020）。

3.  遗传编程（GP）：以表达式或程序为个体的结构搜索。 与 GA 或 DE
    主要输出参数向量不同，GP
    将候选模型表示为可变结构对象（常见为表达式树或程序结构），并通过演化操作在表达空间中生成、重组与筛选模型结构。因而，GP
    在非参数辨识中更接近符号结构发现的概念角色：它不仅拟合数据，更在搜索过程中生成可读的模型表达，从而为机理解释与结构约束提供接口（Quaranta
    et al., 2020）。

从统一视角看，GA、DE 与 GP
的共同点在于以群体承载多样性并通过迭代选择实现改进；差异则在于搜索对象的抽象层级，从数值参数到结构表达逐级上升。

#### 群智能：以粒子协同更新实现分布式寻优

在 Quaranta
等（2020）的综述聚焦下，群智能主要体现为粒子群优化（PSO）。其核心概念可概括为：将候选解视为粒子，在搜索空间中以迭代方式更新位置；更新机制同时利用个体历史最佳与群体或邻域最佳信息，从而在个体探索与群体收敛之间形成协同。

在系统辨识语境中，PSO 的概念定位与 GA 或 DE
类似，主要作为参数辨识的全局寻优器服务于误差最小化目标；其差异点在于，PSO
强调通过信息共享驱动群体趋优，而非依赖显式的交叉或变异算子进行重组（Quaranta
et al., 2020）。这使得 PSO
在实现形态上更贴近协同搜索过程的建模直觉：以群体经验累积来引导搜索轨迹。

#### 神经计算：以人工神经网络实现可学习的动力学映射

与演化计算与群智能主要解决"如何在给定误差准则下搜索最优解"不同，人工神经网络（ANN）在计算智能谱系中的核心贡献是提供一种可学习的函数逼近结构，用于直接表达非线性系统的输入---输出关系或状态演化规律。Quaranta
等（2020）将 ANN 归入
neurocomputing，并将其作为非参数辨识的重要代表之一，其原因在于：

1.  ANN
    能够以层级非线性映射的方式表示复杂关系，从而在结构未知或机理难以完备建模时提供可用的黑箱表达；

2.  在辨识流程中，ANN
    的训练可被视为对网络参数的优化估计，其目标仍由数据一致性（误差或距离）所定义，因此与前述统一的优化表述保持一致；

3.  相较于显式解析模型，ANN
    的结构与参数往往通过学习过程共同确定，使其天然适配"结构---参数耦合"的建模需求（Quaranta
    et al., 2020）。

在本节的概念层面，需要把握的重点并非具体网络结构细节，而是其方法学位置：ANN
为非线性辨识提供了可学习的表示空间，使得"模型类选择"更多体现为对网络表示能力与约束方式的选择，而不仅是对若干显式非线性项的枚举。

#### 小结

无论采用 GA、DE、PSO、GP 还是 ANN，辨识都不可避免地依赖某种差异度量
$g(\cdot)$。Quaranta
等（2020）特别指出：在某些动力学情形下，简单的点对点时间历程误差并不总能充分代表模型质量，例如在具有强敏感性的系统中，轨迹层面的微小初值或参数偏差可能迅速放大，从而使"逐点误差最小"与"动力学行为一致"之间出现张力。由此，差异度量的选择在概念上应被理解为：它不仅决定优化问题的数值形式，更在根本上规定了"模型何谓有效"的评价语义（Quaranta
et al., 2020）。

这一点为本章后续展开奠定了必要的逻辑过渡：智能技术并非以"更强算力"简单替代传统辨识，而是在"搜索机制---表示机制---评价语义"三者耦合下，改变了非线性系统数据驱动建模的可行域与方法边界。

接下来，我们将聚焦于更先进的三种具体智能技术。

### 物理引导与频域增强循环网络：面向非线性时空动力学的预测建模

在上一节对"基于智能技术的非线性系统数据驱动建模路线"进行分类梳理之后，本节进一步选取一种具有代表性的先进深度学习思路展开说明：将可学习的时空表示与可计算的物理更新机制在同一预测框架中耦合，从而在提升多步滚动预测精度的同时，缓解纯黑箱模型在长期一致性与外推鲁棒性方面的结构性风险。该类方法通常面向以场变量演化为特征的非线性动力学系统（如由偏微分方程描述的时空过程），其核心任务是根据历史观测序列生成未来时刻的状态（或观测）序列，实现可用于仿真、预测与后续控制的可微分动力学代理模型。

对时空动力学而言，单纯依赖高容量网络进行端到端序列预测，虽然可在短期内获得较小一步误差，但在自由运行（free-run）模式下往往面临两类关键问题：其一，误差在多步递推中累积并引发动力学漂移，导致长期行为偏离真实系统；其二，高频细节（如边界、尖峰、湍动纹理等）在以均方误差为主的训练准则下易被平滑化，从而损害对关键动力学结构的刻画。基于此，相关工作提出将模型拆解为"数据驱动表征学习加物理一致性更新加高频信息强化"的协同结构：一方面利用深度网络学习难以显式建模的非线性时空相关；另一方面通过显式的数值时间推进机制将预测约束到更合理的动力学轨道附近；同时在频域层面对高频分量加权，以改善对细粒度动态的辨识能力。上述三者共同服务于同一目标，即在预测性能与动力学一致性之间取得更可控的折中。

该类方法通常首先将原始观测场 $x_t$ 映射到潜在表示空间
$u_t$，以降低直接在像素或网格空间递推带来的维度负担，并为后续模块提供统一的特征接口。在结构设计上，一个关键做法是采用双分支潜空间：两条并行分支分别承担"主导时空模式建模"与"误差或残差校正"的功能划分，从而将复杂动力学的学习任务分解为可解释的子目标。

在时空依赖建模方面，空间相关性往往由具备局部---全局建模能力的视觉骨干网络提取，例如基于窗口注意力的
Transformer
结构以兼顾计算可行性与远程依赖表达；时间相关性则由循环单元（如 LSTM
单元）刻画，以形成"空间编码---时间递推"的组合范式。通过这种组合，模型在每一时刻既能提取空间结构特征，又能利用递归状态实现跨时刻的信息传递，为多步预测提供连续的动态记忆。

在双分支框架中，校正分支通常以门控形式对主分支的输出进行补偿，即基于当前输入与隐状态生成校正量，并在输出端与主分支结果融合。该设计的作用在于显式承认可学习模型不可避免存在偏差，并将偏差建模内化为可训练的结构部件，从而减少误差被动累积的风险，并为后续引入物理更新模块预留接口。

为缓解图像或场预测中常见的高频细节丢失问题，方法在潜表示或中间特征上引入频域增强。其基本机制是：将特征映射通过傅里叶变换进入频域，在频谱上施加可学习的滤波或重加权，再经逆变换返回空间域，从而以较低的结构代价注入全局耦合信息，并对高频分量进行显式强调。相较于仅在空间域堆叠卷积或注意力层，频域操作能够以更直接的方式影响谱结构，尤其适用于存在明显波动、边界与尖峰结构的动力学场。

与频域增强相配套，训练阶段可引入频域 $H^1$
型损失，在误差度量中对高频项施加更强权重。该类损失通常在傅里叶域对不同频率
$\xi$
的误差加权，使得频率越高的成分在损失中占比越大，从而推动网络更精确地学习细粒度变化与局部强梯度结构。通过"结构层面的频域模块加目标层面的频域损失"协同，模型对高频动力学信息的表达能力得到系统性增强。

在可学习表征之外，方法的另一核心在于引入物理引导的时间推进机制。对大量时空系统而言，其连续时间演化可抽象为
$$\frac{\partial x}{\partial t}
    =
    \mathcal{F}\big(\partial_x x,\partial_y x,\partial_{xx}x,\ldots\big),$$
即时间导数由若干空间偏导及其非线性组合决定。基于这一结构，模型将"下一步状态预测"部分交由显式的数值积分格式完成，从而把学习任务聚焦到对关键导数项与闭合关系的近似上，避免完全依赖黑箱网络完成时间推进。

具体而言，方法首先用可学习的差分或卷积算子近似空间偏导，例如
$\partial_x$、$\partial_y$、$\partial_{xx}$
等，再将这些偏导量输入到一个可学习映射以得到时间导数近似。为了避免卷积核学习到与偏导算子语义不一致的滤波器，方法进一步引入矩约束（moment
loss）：通过约束卷积核的离散矩与目标导数阶次相匹配，使其更接近具有明确物理含义的差分模板。该约束在训练中相当于对可学习算子施加结构先验，从而提升导数估计的稳定性与可解释性，并降低以任意滤波拟合数据的自由度。

在获得时间导数近似后，方法采用显式的时间积分格式实现状态更新，并以自适应二阶
Runge--Kutta（RK2）为代表：通过在一步内构造中间预测并组合斜率信息，实现比一阶欧拉法更好的精度与稳定性。同时，自适应机制用于根据局部动力学变化调整推进幅度或更新强度，以缓解固定步长在强非线性或刚性片段中的不适配问题。由此，模型输出不再仅是网络直接回归的下一帧，而是网络估计导数加数值积分生成下一帧的物理一致性递推结果，使多步预测更接近真实动力学的演化轨迹。

综合而言，该方法以潜表示时空建模为主干，以频域增强与频域损失强化对高频动力学细节的刻画，并以矩约束导数近似加自适应
RK
积分实现物理引导的显式时间推进，从结构与目标两端同时约束模型的动力学合理性。其总体特征体现了现代深度学习在非线性系统建模中的一种重要发展方向：不满足于短期拟合，而是通过可微分的数值机制与结构性先验，将学习过程嵌入更接近动力学机理的递推框架之中。以此为基础，后续方法将进一步在表示学习、物理约束注入以及不确定性表征等方面扩展，从而形成更系统的先进智能技术驱动的非线性系统数据驱动建模方法谱系。

### 基于 LSTM 自编码器与 Normalizing Flows 的非线性系统数据驱动辨识框架

在非线性系统辨识中，除"学习状态演化算子"这一正向建模任务外，工程上同样常见另一类逆问题：在系统结构已知或可由数值求解器生成响应的前提下，依据观测到的轨迹（位移、速度、流场序列等）反推出控制系统行为的关键参数（如非线性刚度系数、Lorenz
参数或流动的 Reynolds
数）。针对这类"由响应到参数"的辨识目标，文献提出了一种由时序表征学习与可逆概率建模耦合构成的深度学习框架：首先用
LSTM 自编码器从时间序列中提取能够表征系统动力学的低维特征，再用
Normalizing Flows
在概率密度意义下建立特征与系统参数之间的映射，从而实现非线性系统参数的端到端辨识。

该工作将系统辨识明确表述为参数反演问题：给定系统输出（或响应）序列
$R\in\mathbb{R}^n$，目标是确定支配系统行为的参数向量
$P_{\text{sys}}\in\mathbb{R}^s$，并将其抽象为映射
$$P_{\text{sys}} = F(R).$$
由于直接从高维、强非线性、强噪声背景下的轨迹学习 $F$
往往面临可辨识性弱与泛化不稳的问题，文献进一步引入"特征---参数"的中间桥梁：先由特征提取函数
$G$ 从响应中得到动力学特征 $$f = G(R),$$ 再学习参数映射
$$P_{\text{sys}} = K(f).$$
这一分解使得辨识任务由"直接黑箱回归"转化为"表征学习加参数映射"的两阶段耦合框架，从而为后续模型结构设计与损失约束提供了更清晰的工程落点。

当观测对象为流场等高维数据时，文献还在上述链条前端增加了空间降维算子
$\tau$，先将原始流场序列 $R$ 压缩为低维空间特征 $$R' = \tau(R),$$ 再对
$R'$
做时序特征提取与参数映射。由此形成面向不同数据形态的一致范式：空间压缩（可选）、时间表征与参数反演。

在该框架中，LSTM
自编码器承担从轨迹中提取动力学时间特征的核心角色。具体而言，编码器（LSTM-Encoder）将原始时间序列
$X$ 映射为潜在空间中的特征向量 $$\phi = \vartheta(X),$$
解码器（LSTM-Decoder）再将特征反映射回原空间以重构序列
$$\hat{X} = \vartheta^{-1}(\phi).$$
这种编码---解码结构不仅用于降维，更关键的是通过重构约束迫使 $\phi$
保留对轨迹重建必要的关键信息，从而使其具备稳定的动力学语义，例如与频率、幅值演化或混沌吸引子特征相关。文献在非流体算例中直接对轨迹序列使用
LSTM 自编码器；在流体算例中则对空间压缩后的特征序列再施加 LSTM
自编码器，以分离空间模式与时间演化两类结构。

从辨识流程的角度看，这一步相当于在模型结构选择之前先学习一个更适合辨识的表示空间：原始输出序列可能包含大量与参数无关的冗余变化，而
LSTM 编码得到的 $\phi$
旨在聚合与系统动力学本质相关的时序信息，为后续参数映射降低条件数与数据需求。

与常见的回归网络直接输出参数不同，该工作采用 Normalizing Flows 作为特征
$\phi$ 到参数 $Y$ 的映射工具，其关键在于：Normalizing Flows
由一系列可逆且可微的双射变换组成，可通过变量代换公式显式计算目标分布的对数似然，从而实现严格意义上的密度估计。文献以将简单基分布经多层
bijector
变换得到复杂目标分布的链式结构阐释了该思想，并在实现上采用了自回归流（如
masked autoregressive flow），以获得可计算的 Jacobian
与可训练的最大似然目标。

在该框架下，Normalizing Flows
的作用不仅是回归一个点估计，更重要的是将特征与参数之间的关系置于概率密度学习语境中。通过最大化
$\phi$
的似然或最小化负对数似然，模型能够学习到稳定的映射结构，从而在一定程度上缓解不同参数产生相似响应所导致的多解性与不确定性传播问题。

为了使特征可重构、参数可辨识、映射可解释的目标在同一训练过程中协同成立，文献采用了由多项损失加权构成的联合目标函数。以非流体算例为例，总损失由以下三部分构成：

1.  Normalizing Flows 的负对数似然损失，用于密度估计与参数关联；

2.  LSTM 自编码器的轨迹重构损失（均方误差），用于保证特征 $\phi$
    的信息充分性；

3.  辅助特征重构项：将系统参数 $Y$ 输入到 Normalizing
    Flows，并约束其输出与 $\phi$
    的一致性（均方误差），以强化参数与特征之间的耦合可逆性。

对于流体算例，联合损失进一步加入 CNN
自编码器的流场重构项，以同时约束空间压缩表示的可靠性。相应地，整体训练策略体现为多模块共享训练与误差端到端回传，即在同一优化过程中同时更新
LSTM、Normalizing Flows 以及 CNN
各子网络参数，使得空间特征、时间特征与参数映射在同一统计目标下对齐。

该文以多个具有代表性的非线性系统作为验证对象，包括二维自由度 Duffing
振子与 Lorenz
系统，并进一步扩展到圆柱绕流与方腔顶盖驱动流等二维流体问题。其数据生成方式体现了参数扰动、响应采样与监督反演相结合的基本范式：通过数值求解器在不同参数采样下生成响应序列，将响应作为输入、参数作为监督标签训练网络；流体问题则以不同
Reynolds 数下的流场序列作为输入，目标输出为 Reynolds
数。文献同时讨论了多参数同时变化会增加辨识难度并导致性能下降的问题，并指出方法在参数变化范围与真实实验验证方面仍存在边界与改进空间。

综上，该框架的学术价值可概括为：在非线性系统参数辨识这一典型逆问题上，将时序表征学习（LSTM
自编码器）与可逆概率建模（Normalizing
Flows）进行结构化耦合，并通过多目标损失将可重构表示与可辨识参数映射统一到端到端训练流程中，从而形成一条相对通用的深度辨识路径。更重要的是，这一思路在方法论上为本章后续内容提供了自然过渡：一方面，它展示了现代深度学习如何通过表示学习降低非线性辨识的结构不确定性；另一方面，它也提示了先进智能技术在动力系统建模中需要系统面对的关键问题，包括多参数耦合下的可辨识性退化、分布外工况的外推可信度，以及从数值数据走向真实实验数据时的鲁棒性与一致性检验。

### 基于深度学习的 Koopman 本征函数辨识（Koopman Network）

在第二章关于"算子理论与变换方法"的讨论中，我们已经指出：Koopman
理论通过将非线性系统的演化提升到可观测函数空间，从而以线性算子刻画非线性动力学；相应地，DMD
与 EDMD
等数据驱动近似方法可在有限维特征空间内回归得到线性推进算子。该范式的关键优势在于为预测、降阶与控制提供了统一的线性框架，但其工程落地的瓶颈同样清晰------可观测量（特征映射）的选择决定线性化质量，而手工构造的字典往往在表达能力、维数灾难与噪声敏感性之间难以兼顾。基于此，近年来形成了一类具有代表性的"智能增强"路线：利用深度神经网络自动学习
Koopman 语境下的低维内禀坐标与线性推进算子，以缓解传统 EDMD
对人工基函数与特征工程的依赖，并力图在保持可解释性的同时提升模型的紧致性与预测一致性。

Koopman
算子框架的核心对象是本征函数及其诱导的线性演化结构。然而，对强非线性系统而言，本征函数往往难以显式求得，且当系统存在连续谱时，例如非线性振子中能量变化引起的频率漂移，用少量固定频率的本征函数进行有限维逼近会遭遇结构性困难，常表现为需要引入大量高次谐波项才能覆盖频率随相空间位置变化的现象，从而导致表示冗余与可解释性下降。针对这一问题，Koopman
Network 的基本思想是：用深度网络学习一个编码映射 $\phi$ 将原状态 $x$
映射到低维"本征函数坐标"
$$y = \phi(x),$$
并在该坐标中学习线性动力学
$$y_{k+1} = K y_k.$$
同时再用解码映射 $\phi^{-1}$ 将 $y$
还原到原空间，以确保该表示不仅线性可推进，也可重构、可预测。这一构造将第二章中
Koopman 与 EDMD
的升维线性化思想转化为一个可端到端训练的表示学习问题，即本征函数或其近似形式不再由人工字典给出，而由网络从轨迹数据中自动生成。

该方法以深度自编码器为骨架：编码器 $\phi$ 提取低维内禀坐标 $y$，解码器
$\phi^{-1}$ 负责从 $y$ 重构状态 $x$。在此基础上，引入线性推进矩阵 $K$
使得内禀坐标满足近似线性递推
$$y_{k+1} = \phi(x_{k+1}) \approx K \phi(x_k) = K y_k,$$
并进一步通过多步约束提升滚动预测的一致性
$$\phi(x_{k+m}) \approx K^m \phi(x_k).$$
由此，网络训练不再仅追求静态重构精度，而是显式把动力学一致性编码进损失函数，使学习到的坐标更接近
Koopman 意义下可线性演化的坐标系。

与仅在特征空间拟合线性回归的传统 EDMD 不同，Koopman Network
进一步强调可预测的闭环，利用
$$\hat{x}_{k+1} = \phi^{-1}\big(K \phi(x_k)\big),$$
以及
$$\hat{x}_{k+m} = \phi^{-1}\big(K^m \phi(x_k)\big)$$
直接在原状态空间定义预测输出，并将其纳入训练约束。这一设计使模型的优化目标与第二章强调的多步预测与自由运行一致性更直接对齐，从而避免仅在一步拟合意义下得到表面线性、长期漂移的表示。

该框架将训练目标组织为三类互补约束：（i）自编码重构约束保证坐标具有信息完备性；（ii）线性动力学约束保证
Koopman
形式的线性推进成立；（iii）未来状态预测约束保证该线性推进在原空间具有可用的预测意义。文献给出的显式损失由三项加权均方误差构成，并辅以正则化以降低过拟合风险，整体形式可概括为
$$\mathcal{L}
    =
    \alpha_1 \big(\mathcal{L}_{\text{recon}} + \mathcal{L}_{\text{pred}}\big)
    +
    \mathcal{L}_{\text{lin}}
    +
    \alpha_2 \mathcal{L}_1
    +
    \alpha_3 \|W\|_2^2,$$ 其中 $\mathcal{L}_{\text{recon}}$ 约束
$\phi^{-1}(\phi(x)) \approx x$，$\mathcal{L}_{\text{lin}}$ 约束
$\phi(x_{k+m}) \approx K^m \phi(x_k)$，$\mathcal{L}_{\text{pred}}$ 约束
$\phi^{-1}\big(K^m \phi(x_k)\big) \approx x_{k+m}$。多步项的引入强调了在若干步长上的线性一致性与可预测性，从而在训练阶段即对长期滚动误差积累施加抑制。

第二章已经指出，Koopman
线性化的有效性高度依赖谱结构。当系统存在连续谱时，固定本征值的有限维线性模型往往难以用少量本征函数实现紧致表示。为应对这一类广泛存在于非线性振动与流体问题中的现象，文献提出在网络中引入辅助网络
$\Lambda(\cdot)$，使线性推进矩阵 $K$
的本征值随相空间位置或内禀坐标变化，即令 $$\lambda = \Lambda(y),$$
并采用依赖于 $\lambda$ 的线性推进 $$y_{k+1} = K(\lambda) y_k.$$
在实现上，针对共轭复本征值 $\lambda_{\pm} = \mu \pm i \omega$，将 $K$
组织为由若干 $2 \times 2$ 的 Jordan 或旋转缩放块构成的块对角结构，并用
$\mu$ 与 $\omega$
参数化该块，从而在离散时间下对应衰减率与频率的可解释线性演化形式。该结构允许频率随轨道能量或相空间位置连续变化，从机制上避免了用高维网络堆叠谐波项来拟合频率漂移的被动做法，从而提升表示紧致性与可解释性。

进一步地，为增强坐标的几何可解释性，文献在振子类系统中引入径向对称的参数化策略，使本征值的变化主要依赖于内禀坐标的半径，例如
$$R^2 = y_1^2 + y_2^2,$$
从而使轨道在本征函数坐标中呈现近似圆轨道的线性结构。这一约束不仅改善了训练的可辨识性，也使学习到的表示更贴近经典动力系统中的作用---角度类坐标解释。

文献通过多个例子展示了该框架在不同谱结构下的适用性，包括离散谱的低维非线性系统、具有连续谱特征的非线性摆，以及与涡脱落相关的高维流动，例如以经典圆柱绕流的低维平均场模型为基准的算例。这些算例共同说明：当训练数据能够覆盖系统的主要吸引子与关键瞬态过程时，网络可在低维内禀坐标中恢复近似线性推进，并实现对轨迹的重构与预测；尤其在连续谱问题中，引入辅助网络的参数化
$K(\lambda)$ 有助于用更少的本征函数获得更紧致的表示。

与此同时，文献亦明确指出该路线在工程应用中的若干关键约束：其一，模型的泛化能力依赖训练数据的体量与多样性；其二，内禀维数
$p$
的选择仍是影响稳定性与可解释性的核心超参数之一；其三，更一般的高维谱结构以及谱类型的自动判别仍需要进一步方法发展。上述边界与第二章对数据驱动模型外推与长期一致性风险的分析是相互呼应的：深度学习在提供强表示能力的同时，必须通过结构化约束，如
Koopman
线性推进与谱结构参数化，来抑制高容量插值器的外推不确定性，并将学习结果锚定在可解释的动力系统语义之上。
